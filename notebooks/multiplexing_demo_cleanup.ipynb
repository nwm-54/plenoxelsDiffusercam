{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2f3b9a1",
   "metadata": {},
   "source": [
    "# Multiplexing Pixels Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bc669e-7311-4be2-9a16-e2a2f5d3db79",
   "metadata": {},
   "source": [
    "## Generating multiplexed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c86cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from typing import Tuple, List\n",
    "from kornia.enhance import equalize_clahe\n",
    "\n",
    "\n",
    "def get_comap(\n",
    "    num_lens: int, d_lens_sensor: int, H: int, W: int\n",
    ") -> Tuple[np.ndarray, List[int]]:\n",
    "    # Verify input and calculate the grid dimensions\n",
    "    if math.sqrt(num_lens) ** 2 == num_lens:\n",
    "        num_lenses_yx = [int(math.sqrt(num_lens)), int(math.sqrt(num_lens))]\n",
    "    else:\n",
    "        print(\"Number of sublens should be a square number\")\n",
    "        assert False\n",
    "\n",
    "    # Calculate microlens dimensions in pixels based on d_lens_sensor\n",
    "    base_microlens_size = min(H // num_lenses_yx[0], W // num_lenses_yx[1]) // 12\n",
    "    microlens_height = int(base_microlens_size * d_lens_sensor)\n",
    "    microlens_height = microlens_height - (\n",
    "        microlens_height % 2\n",
    "    )  # Make dimensions even for convenience\n",
    "    microlens_width = microlens_height  # Keep microlenses square\n",
    "    comap_yx = -np.ones((num_lens, H, W, 2))\n",
    "\n",
    "    # Calculate positions for microlenses to distribute from edge to edge\n",
    "    if num_lenses_yx[0] > 1:\n",
    "        y_positions = np.linspace(\n",
    "            microlens_height // 2,  # First lens centered at top edge + half lens height\n",
    "            H\n",
    "            - microlens_height\n",
    "            // 2,  # Last lens centered at bottom edge - half lens height\n",
    "            num_lenses_yx[0],\n",
    "        )\n",
    "    else:\n",
    "        y_positions = np.array([H // 2])  # If only one row, place it in the center\n",
    "    if num_lenses_yx[1] > 1:\n",
    "        x_positions = np.linspace(\n",
    "            microlens_width // 2,  # First lens centered at left edge + half lens width\n",
    "            W\n",
    "            - microlens_width\n",
    "            // 2,  # Last lens centered at right edge - half lens width\n",
    "            num_lenses_yx[1],\n",
    "        )\n",
    "    else:\n",
    "        x_positions = np.array([W // 2])  # If only one column, place it in the center\n",
    "\n",
    "    for i in range(num_lens):\n",
    "        row, col = i // num_lenses_yx[1], i % num_lenses_yx[1]\n",
    "        center_y, center_x = int(y_positions[row]), int(x_positions[col])\n",
    "        start_y = int(max(0, center_y - microlens_height // 2))\n",
    "        end_y = int(min(H, center_y + microlens_height // 2))\n",
    "        start_x = int(max(0, center_x - microlens_width // 2))\n",
    "        end_x = int(min(W, center_x + microlens_width // 2))\n",
    "\n",
    "        for y in range(start_y, end_y):\n",
    "            for x in range(start_x, end_x):\n",
    "                local_y, local_x = y - start_y, x - start_x\n",
    "                comap_yx[i, y, x, 0] = local_y\n",
    "                comap_yx[i, y, x, 1] = local_x\n",
    "\n",
    "    # Return the original dimension as second return value\n",
    "    dim_lens_lf_yx = [microlens_height, microlens_width]\n",
    "    return comap_yx, dim_lens_lf_yx\n",
    "\n",
    "\n",
    "def read_images(num_lens, model_path, base):\n",
    "    images = []\n",
    "    for j in range(num_lens):\n",
    "        sub_lens_path = f\"r_{base}_{j}.png\"\n",
    "        im_gt = (\n",
    "            imageio.imread(f\"{model_path}/{sub_lens_path}\").astype(np.float32) / 255.0\n",
    "        )\n",
    "        im_tensor = torch.from_numpy(im_gt[:, :, :3]).permute(2, 0, 1).to(device)\n",
    "        images.append(im_tensor)  # Keep only RGB channels\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "def get_max_overlap(comap_yx, num_lens, H, W):\n",
    "    overlap_count = torch.zeros(H, W, dtype=torch.int32, device=device)\n",
    "    for i in range(num_lens):\n",
    "        valid_mask = comap_yx[i][:, :, 1] != -1\n",
    "        overlap_count += valid_mask\n",
    "    return overlap_count.max()\n",
    "\n",
    "\n",
    "def generate_sub_images(images, comap_yx, dim_lens_lf_yx, num_lens, sensor_size):\n",
    "    sub_images = torch.zeros(\n",
    "        num_lens, 3, sensor_size, sensor_size, device=device, dtype=torch.float32\n",
    "    )\n",
    "\n",
    "    # Create a mapping from comap_yx index to images index\n",
    "    grid_size = int(math.sqrt(num_lens))\n",
    "    idx = torch.arange(grid_size, device=device)\n",
    "    grid_i, grid_j = torch.meshgrid(idx, idx, indexing=\"ij\")\n",
    "    mapping = ((grid_size - 1 - grid_i) + (grid_size - 1 - grid_j) * grid_size).reshape(\n",
    "        -1\n",
    "    )\n",
    "\n",
    "    images_tensor = torch.stack(images, dim=0).to(device)\n",
    "    selected_images = images_tensor[mapping]\n",
    "    resized_images = F.interpolate(\n",
    "        selected_images,\n",
    "        size=(dim_lens_lf_yx[0], dim_lens_lf_yx[1]),\n",
    "        mode=\"bilinear\",\n",
    "        align_corners=False,\n",
    "    )\n",
    "\n",
    "    for i in range(num_lens):\n",
    "        # sub_image = torch.zeros(3, sensor_size, sensor_size, device=device, dtype=torch.float32)\n",
    "        y_coords = comap_yx[i, :, :, 0]\n",
    "        x_coords = comap_yx[i, :, :, 1]\n",
    "\n",
    "        valid_mask = (\n",
    "            (y_coords != -1)\n",
    "            & (x_coords != -1)\n",
    "            & (y_coords >= 0)\n",
    "            & (y_coords < dim_lens_lf_yx[0])\n",
    "            & (x_coords >= 0)\n",
    "            & (x_coords < dim_lens_lf_yx[1])\n",
    "        )\n",
    "\n",
    "        if valid_mask.any():\n",
    "            y_indices, x_indices = torch.where(valid_mask)\n",
    "            y_src = y_coords[valid_mask].int()\n",
    "            x_src = x_coords[valid_mask].int()\n",
    "        sub_images[i, :, y_indices, x_indices] = resized_images[i, :, y_src, x_src]\n",
    "\n",
    "    return sub_images\n",
    "\n",
    "\n",
    "def generate(images, comap_yx, dim_lens_lf_yx, num_lens, H, W, max_overlap):\n",
    "    grid_size = int(math.sqrt(num_lens))\n",
    "    idx = torch.arange(grid_size, device=device)\n",
    "    grid_i, grid_j = torch.meshgrid(idx, idx, indexing=\"ij\")\n",
    "    mapping = ((grid_size - 1 - grid_i) + (grid_size - 1 - grid_j) * grid_size).reshape(\n",
    "        -1\n",
    "    )\n",
    "\n",
    "    images_tensor = torch.stack(images, dim=0).to(device)\n",
    "    selected_images = images_tensor[mapping]\n",
    "    resized_images = F.interpolate(\n",
    "        selected_images,\n",
    "        size=(dim_lens_lf_yx[0], dim_lens_lf_yx[1]),\n",
    "        mode=\"bilinear\",\n",
    "        align_corners=False,\n",
    "    )\n",
    "\n",
    "    output_image = torch.zeros(3, H, W, device=device, dtype=torch.float32)\n",
    "    for i in range(num_lens):\n",
    "        y_coords = comap_yx[i, :, :, 0]\n",
    "        x_coords = comap_yx[i, :, :, 1]\n",
    "\n",
    "        valid_mask = (\n",
    "            (y_coords != -1)\n",
    "            & (x_coords != -1)\n",
    "            & (y_coords >= 0)\n",
    "            & (y_coords < dim_lens_lf_yx[0])\n",
    "            & (x_coords >= 0)\n",
    "            & (x_coords < dim_lens_lf_yx[1])\n",
    "        )\n",
    "\n",
    "        # Only process this microlens if there are any valid mapping positions.\n",
    "        if valid_mask.any():\n",
    "            # Get 2D indices within the sub-image where valid_mask is True.\n",
    "            y_indices, x_indices = torch.where(valid_mask)\n",
    "            y_src = y_coords[valid_mask].long()\n",
    "            x_src = x_coords[valid_mask].long()\n",
    "            output_image[:, y_indices, x_indices] += resized_images[i, :, y_src, x_src]\n",
    "\n",
    "    output_image = torch.div(output_image, max_overlap)\n",
    "    return output_image\n",
    "\n",
    "\n",
    "def plot_sub_images(sub_images, num_lens):\n",
    "    grid_size = int(np.sqrt(num_lens))\n",
    "    fig, axes = plt.subplots(grid_size, grid_size, figsize=(15, 15))\n",
    "\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            idx = i * grid_size + j\n",
    "            axes[i, j].imshow(sub_images[idx].cpu().permute(1, 2, 0).numpy())\n",
    "            axes[i, j].set_title(f\"Microlens {idx}\")\n",
    "            axes[i, j].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "NUM_LENS = 16\n",
    "SENSOR_SIZE = 800\n",
    "d_lens_sensor = 18\n",
    "model_path = \"/home/wl757/multiplexed-pixels/plenoxels/blender_data/lego_gen12/new_multiplexed_views\"\n",
    "base = \"59\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Generate coordinate mapping\n",
    "comap_yx, dim_lens_lf_yx = get_comap(NUM_LENS, d_lens_sensor, SENSOR_SIZE, SENSOR_SIZE)\n",
    "print(dim_lens_lf_yx)\n",
    "# plt.imshow(comap_yx[0, :, :, 0])\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "comap_yx = torch.from_numpy(comap_yx).to(device)\n",
    "\n",
    "# Generate and get sub-images\n",
    "images = read_images(NUM_LENS, model_path, base)\n",
    "max_overlap = get_max_overlap(comap_yx, NUM_LENS, SENSOR_SIZE, SENSOR_SIZE)\n",
    "combined = generate(\n",
    "    images, comap_yx, dim_lens_lf_yx, NUM_LENS, SENSOR_SIZE, SENSOR_SIZE, max_overlap\n",
    ")\n",
    "print(max_overlap)\n",
    "\n",
    "print(combined.min(), combined.max())\n",
    "plt.imshow(combined.cpu().permute(1, 2, 0).numpy())\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a0821e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from kornia.enhance.equalization import equalize_clahe\n",
    "\n",
    "with torch.autograd.detect_anomaly():\n",
    "    img = torch.rand((2, 3, 10, 20), requires_grad=True)\n",
    "    res = equalize_clahe(img, slow_and_differentiable=True)\n",
    "    res.sum().backward()\n",
    "    print(img.grad, img.grad.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1244e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "\n",
    "def get_comap(num_lens, d_lens_sensor, H, W):\n",
    "    if math.sqrt(num_lens) ** 2 == num_lens:\n",
    "        num_lenses_yx = [int(math.sqrt(num_lens)), int(math.sqrt(num_lens))]\n",
    "    else:\n",
    "        print(\"Number of sublens should be a square number\")\n",
    "        assert False\n",
    "\n",
    "    base_microlens_size = min(H // num_lenses_yx[0], W // num_lenses_yx[1]) // 12\n",
    "    microlens_height = int(base_microlens_size * d_lens_sensor)\n",
    "    microlens_height = microlens_height - (\n",
    "        microlens_height % 2\n",
    "    )  # Make dimensions even for convenience\n",
    "    microlens_width = microlens_height  # Keep microlenses square\n",
    "    comap_yx = -np.ones((num_lens, H, W, 2))\n",
    "\n",
    "    if num_lenses_yx[0] > 1:\n",
    "        y_positions = np.linspace(\n",
    "            microlens_height // 2,  # First lens centered at top edge + half lens height\n",
    "            H\n",
    "            - microlens_height\n",
    "            // 2,  # Last lens centered at bottom edge - half lens height\n",
    "            num_lenses_yx[0],\n",
    "        )\n",
    "    else:\n",
    "        y_positions = np.array([H // 2])  # If only one row, place it in the center\n",
    "    if num_lenses_yx[1] > 1:\n",
    "        x_positions = np.linspace(\n",
    "            microlens_width // 2,  # First lens centered at left edge + half lens width\n",
    "            W\n",
    "            - microlens_width\n",
    "            // 2,  # Last lens centered at right edge - half lens width\n",
    "            num_lenses_yx[1],\n",
    "        )\n",
    "    else:\n",
    "        x_positions = np.array([W // 2])  # If only one column, place it in the center\n",
    "\n",
    "    for i in range(num_lens):\n",
    "        row, col = i // num_lenses_yx[1], i % num_lenses_yx[1]\n",
    "        center_y, center_x = int(y_positions[row]), int(x_positions[col])\n",
    "        start_y = int(max(0, center_y - microlens_height // 2))\n",
    "        end_y = int(min(H, center_y + microlens_height // 2))\n",
    "        start_x = int(max(0, center_x - microlens_width // 2))\n",
    "        end_x = int(min(W, center_x + microlens_width // 2))\n",
    "\n",
    "        for y in range(start_y, end_y):\n",
    "            for x in range(start_x, end_x):\n",
    "                local_y, local_x = y - start_y, x - start_x\n",
    "                comap_yx[i, y, x, 0] = local_y\n",
    "                comap_yx[i, y, x, 1] = local_x\n",
    "\n",
    "    dim_lens_lf_yx = [microlens_height, microlens_width]\n",
    "    return comap_yx, dim_lens_lf_yx\n",
    "\n",
    "\n",
    "def read_images(num_lens, model_path, base):\n",
    "    images = []\n",
    "    for j in range(num_lens):\n",
    "        sub_lens_path = f\"r_{base}_{j}.png\"\n",
    "        im_gt = (\n",
    "            imageio.imread(f\"{model_path}/{sub_lens_path}\").astype(np.float32) / 255.0\n",
    "        )\n",
    "        im_tensor = torch.from_numpy(im_gt[:, :, :3]).permute(2, 0, 1).to(device)\n",
    "        images.append(im_tensor)  # Keep only RGB channels\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "def get_max_overlap(comap_yx, num_lens, H, W):\n",
    "    overlap_count = torch.zeros(H, W, dtype=torch.int32, device=device)\n",
    "    for i in range(num_lens):\n",
    "        valid_mask = comap_yx[i][:, :, 1] != -1\n",
    "        overlap_count += valid_mask\n",
    "    return overlap_count.max()\n",
    "\n",
    "\n",
    "def generate_sub_images(images, comap_yx, dim_lens_lf_yx, num_lens, sensor_size):\n",
    "    sub_images = torch.zeros(\n",
    "        num_lens, 3, sensor_size, sensor_size, device=device, dtype=torch.float32\n",
    "    )\n",
    "\n",
    "    # Create a mapping from comap_yx index to images index\n",
    "    grid_size = int(math.sqrt(num_lens))\n",
    "    idx = torch.arange(grid_size, device=device)\n",
    "    grid_i, grid_j = torch.meshgrid(idx, idx, indexing=\"ij\")\n",
    "    mapping = ((grid_size - 1 - grid_i) + (grid_size - 1 - grid_j) * grid_size).reshape(\n",
    "        -1\n",
    "    )\n",
    "\n",
    "    images_tensor = torch.stack(images, dim=0).to(device)\n",
    "    selected_images = images_tensor[mapping]\n",
    "    resized_images = F.interpolate(\n",
    "        selected_images,\n",
    "        size=(dim_lens_lf_yx[0], dim_lens_lf_yx[1]),\n",
    "        mode=\"bilinear\",\n",
    "        align_corners=False,\n",
    "    )\n",
    "\n",
    "    for i in range(num_lens):\n",
    "        # sub_image = torch.zeros(3, sensor_size, sensor_size, device=device, dtype=torch.float32)\n",
    "        y_coords = comap_yx[i, :, :, 0]\n",
    "        x_coords = comap_yx[i, :, :, 1]\n",
    "\n",
    "        valid_mask = (\n",
    "            (y_coords != -1)\n",
    "            & (x_coords != -1)\n",
    "            & (y_coords >= 0)\n",
    "            & (y_coords < dim_lens_lf_yx[0])\n",
    "            & (x_coords >= 0)\n",
    "            & (x_coords < dim_lens_lf_yx[1])\n",
    "        )\n",
    "\n",
    "        if valid_mask.any():\n",
    "            y_indices, x_indices = torch.where(valid_mask)\n",
    "            y_src = y_coords[valid_mask].int()\n",
    "            x_src = x_coords[valid_mask].int()\n",
    "        sub_images[i, :, y_indices, x_indices] = resized_images[i, :, y_src, x_src]\n",
    "\n",
    "    return sub_images\n",
    "\n",
    "\n",
    "def plot_sub_images(sub_images, num_lens):\n",
    "    grid_size = int(np.sqrt(num_lens))\n",
    "    fig, axes = plt.subplots(grid_size, grid_size, figsize=(15, 15))\n",
    "\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            idx = i * grid_size + j\n",
    "            axes[i, j].imshow(sub_images[idx].cpu().permute(1, 2, 0).numpy())\n",
    "            axes[i, j].set_title(f\"Microlens {idx}\")\n",
    "            axes[i, j].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "NUM_LENS = 16\n",
    "SENSOR_SIZE = 400\n",
    "d_lens_sensor = 19\n",
    "model_path = \"/home/wl757/multiplexed-pixels/plenoxels/blender_data/lego_gen12/train_multilens_16_black\"\n",
    "base = \"59\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Generate coordinate mapping\n",
    "comap_yx, dim_lens_lf_yx = get_comap(NUM_LENS, d_lens_sensor, SENSOR_SIZE, SENSOR_SIZE)\n",
    "print(dim_lens_lf_yx)\n",
    "# plt.imshow(comap_yx[0, :, :, 0])\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "comap_yx = torch.from_numpy(comap_yx).to(device)\n",
    "\n",
    "# Generate and get sub-images\n",
    "images = read_images(NUM_LENS, model_path, base)\n",
    "sub_images = generate_sub_images(\n",
    "    images, comap_yx, dim_lens_lf_yx, NUM_LENS, SENSOR_SIZE\n",
    ")\n",
    "max_overlap = get_max_overlap(comap_yx, NUM_LENS, SENSOR_SIZE, SENSOR_SIZE)\n",
    "print(max_overlap)\n",
    "\n",
    "# Plot all sub-images\n",
    "# plot_sub_images(sub_images, NUM_LENS)\n",
    "combined = torch.sum(sub_images, axis=0)\n",
    "combined = combined / combined.max()\n",
    "plt.imshow(combined.cpu().permute(1, 2, 0).numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e973ab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from kornia import enhance\n",
    "import torch\n",
    "\n",
    "\n",
    "def get_comap(num_lens, d_lens_sensor, H, W):\n",
    "    if math.sqrt(num_lens) ** 2 == num_lens:\n",
    "        num_lenses_yx = [int(math.sqrt(num_lens)), int(math.sqrt(num_lens))]\n",
    "    else:\n",
    "        print(\"Number of sublens should be a square number\")\n",
    "        assert False\n",
    "\n",
    "    # Calculate microlens dimensions in pixels based on d_lens_sensor\n",
    "    base_microlens_size = min(H // num_lenses_yx[0], W // num_lenses_yx[1]) // 12\n",
    "    microlens_height = int(base_microlens_size * d_lens_sensor)\n",
    "    microlens_height = microlens_height - (\n",
    "        microlens_height % 2\n",
    "    )  # Make dimensions even for convenience\n",
    "    microlens_width = microlens_height  # Keep microlenses square\n",
    "    comap_yx = -np.ones((num_lens, H, W, 2))\n",
    "\n",
    "    # Calculate positions for microlenses to distribute from edge to edge\n",
    "    if num_lenses_yx[0] > 1:\n",
    "        y_positions = np.linspace(\n",
    "            microlens_height // 2,  # First lens centered at top edge + half lens height\n",
    "            H\n",
    "            - microlens_height\n",
    "            // 2,  # Last lens centered at bottom edge - half lens height\n",
    "            num_lenses_yx[0],\n",
    "        )\n",
    "    else:\n",
    "        y_positions = np.array([H // 2])  # If only one row, place it in the center\n",
    "    if num_lenses_yx[1] > 1:\n",
    "        x_positions = np.linspace(\n",
    "            microlens_width // 2,  # First lens centered at left edge + half lens width\n",
    "            W\n",
    "            - microlens_width\n",
    "            // 2,  # Last lens centered at right edge - half lens width\n",
    "            num_lenses_yx[1],\n",
    "        )\n",
    "    else:\n",
    "        x_positions = np.array([W // 2])  # If only one column, place it in the center\n",
    "\n",
    "    for i in range(num_lens):\n",
    "        row, col = i // num_lenses_yx[1], i % num_lenses_yx[1]\n",
    "        center_y, center_x = int(y_positions[row]), int(x_positions[col])\n",
    "        start_y = int(max(0, center_y - microlens_height // 2))\n",
    "        end_y = int(min(H, center_y + microlens_height // 2))\n",
    "        start_x = int(max(0, center_x - microlens_width // 2))\n",
    "        end_x = int(min(W, center_x + microlens_width // 2))\n",
    "\n",
    "        for y in range(start_y, end_y):\n",
    "            for x in range(start_x, end_x):\n",
    "                local_y, local_x = y - start_y, x - start_x\n",
    "                comap_yx[i, y, x, 0] = local_y\n",
    "                comap_yx[i, y, x, 1] = local_x\n",
    "\n",
    "    # Return the original dimension as second return value\n",
    "    dim_lens_lf_yx = [microlens_height, microlens_width]\n",
    "    return comap_yx, dim_lens_lf_yx\n",
    "\n",
    "\n",
    "def read_images(num_lens, model_path, base):\n",
    "    images = []\n",
    "    for j in range(num_lens):\n",
    "        sub_lens_path = f\"r_{base}_{j}.png\"\n",
    "        im_gt = (\n",
    "            imageio.imread(f\"{model_path}/{sub_lens_path}\").astype(np.float32) / 255.0\n",
    "        )\n",
    "        images.append(im_gt[:, :, :3])  # Keep only RGB channels\n",
    "    return images\n",
    "\n",
    "\n",
    "def generate_alpha_map(comap_yx, num_lens, H, W):\n",
    "    overlap_count = np.zeros((H, W), dtype=np.int32)\n",
    "\n",
    "    for i in range(num_lens):\n",
    "        valid_mask = comap_yx[i, :, :, 0] != -1\n",
    "        overlap_count += valid_mask\n",
    "\n",
    "    alpha_map = np.zeros((H, W))\n",
    "    non_zero_mask = overlap_count > 0\n",
    "    alpha_map[non_zero_mask] = 1.0 / overlap_count[non_zero_mask]\n",
    "    return alpha_map, overlap_count\n",
    "\n",
    "\n",
    "def generate_sub_images(images, comap_yx, dim_lens_lf_yx, num_lens, sensor_size):\n",
    "    sub_images = []\n",
    "    alpha_map, _ = generate_alpha_map(comap_yx, num_lens, sensor_size, sensor_size)\n",
    "\n",
    "    # Create a mapping from comap_yx index to images index\n",
    "    grid_size = int(np.sqrt(num_lens))\n",
    "    mapping = np.zeros(num_lens, dtype=int)\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            comap_idx = i * grid_size + j\n",
    "            images_idx = (grid_size - 1 - i) + (grid_size - 1 - j) * grid_size\n",
    "            mapping[comap_idx] = images_idx\n",
    "\n",
    "    resized_images = [\n",
    "        resize(\n",
    "            images[mapping[i]],\n",
    "            (dim_lens_lf_yx[0], dim_lens_lf_yx[1]),\n",
    "            anti_aliasing=True,\n",
    "        )\n",
    "        for i in range(num_lens)\n",
    "    ]\n",
    "\n",
    "    for i in range(num_lens):\n",
    "        sub_image = np.zeros((sensor_size, sensor_size, 4))\n",
    "        y_coords = comap_yx[i, :, :, 0]\n",
    "        x_coords = comap_yx[i, :, :, 1]\n",
    "\n",
    "        valid_mask = (y_coords != -1) & (x_coords != -1)\n",
    "\n",
    "        y_in_bounds = (y_coords >= 0) & (y_coords < dim_lens_lf_yx[0])\n",
    "        x_in_bounds = (x_coords >= 0) & (x_coords < dim_lens_lf_yx[1])\n",
    "        valid_mask = valid_mask & y_in_bounds & x_in_bounds\n",
    "\n",
    "        y_indices, x_indices = np.where(valid_mask)\n",
    "        y_src = y_coords[valid_mask].astype(int)\n",
    "        x_src = x_coords[valid_mask].astype(int)\n",
    "        sub_image[y_indices, x_indices, :3] = resized_images[i][y_src, x_src]\n",
    "        sub_image[:, :, 3] = alpha_map\n",
    "\n",
    "        sub_images.append(sub_image)\n",
    "\n",
    "    return sub_images\n",
    "\n",
    "\n",
    "def plot_sub_images(sub_images, num_lens):\n",
    "    # Calculate grid dimensions (assuming num_lens is a perfect square)\n",
    "    grid_size = int(np.sqrt(num_lens))\n",
    "\n",
    "    # Create a figure with subplots\n",
    "    fig, axes = plt.subplots(grid_size, grid_size, figsize=(15, 15))\n",
    "\n",
    "    # Plot each sub-image in the correct grid position corresponding to comap_yx ordering\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            idx = i * grid_size + j\n",
    "            axes[i, j].imshow(sub_images[idx])\n",
    "            axes[i, j].set_title(f\"Microlens {idx}\")\n",
    "            axes[i, j].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "NUM_LENS = 16\n",
    "SENSOR_SIZE = 800\n",
    "d_lens_sensor = 20\n",
    "model_path = \"/home/wl757/multiplexed-pixels/plenoxels/blender_data/lego_gen12/train_multilens_16_black\"\n",
    "base = \"59\"\n",
    "\n",
    "# Generate coordinate mapping\n",
    "comap_yx, dim_lens_lf_yx = get_comap(NUM_LENS, d_lens_sensor, SENSOR_SIZE, SENSOR_SIZE)\n",
    "# print(dim_lens_lf_yx)\n",
    "# plt.imshow(comap_yx[0, :, :, 0])\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "alpha_map, overlap_count = generate_alpha_map(\n",
    "    comap_yx, NUM_LENS, SENSOR_SIZE, SENSOR_SIZE\n",
    ")\n",
    "# plt.imshow(alpha_map)\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "# Generate and get sub-images\n",
    "images = read_images(NUM_LENS, model_path, base)\n",
    "sub_images = generate_sub_images(\n",
    "    images, comap_yx, dim_lens_lf_yx, NUM_LENS, SENSOR_SIZE\n",
    ")\n",
    "\n",
    "# Plot all sub-images\n",
    "# plot_sub_images(sub_images, NUM_LENS)\n",
    "combined = np.sum(sub_images, axis=0)\n",
    "output = np.zeros((SENSOR_SIZE, SENSOR_SIZE, 3))\n",
    "for image in sub_images:\n",
    "    rgb = image[:, :, :3]\n",
    "    alpha = image[:, :, 3]\n",
    "    output += rgb * alpha[:, :, np.newaxis]\n",
    "combined_rgb = combined[:, :, :3]\n",
    "print(\"overlap max: \", overlap_count.max())\n",
    "print(\"overlap min: \", overlap_count.min())\n",
    "combined_output = combined_rgb / overlap_count.max()\n",
    "# combined_output = combined_output / combined_output.max()\n",
    "print(combined_output.min(), combined_output.max())\n",
    "plt.imshow(combined_rgb / combined_rgb.max())\n",
    "plt.show()\n",
    "plt.imshow(combined_output)\n",
    "plt.show()\n",
    "plt.imshow(\n",
    "    enhance.equalize(torch.from_numpy(combined_output).permute(2, 0, 1))\n",
    "    .permute(1, 2, 0)\n",
    "    .detach()\n",
    "    .numpy()\n",
    ")\n",
    "plt.show()\n",
    "plt.imshow(combined)\n",
    "plt.show()\n",
    "plt.imshow(output)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076f27ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def get_comap(num_lens, d_lens_sensor, H, W):\n",
    "    if math.sqrt(num_lens) ** 2 == num_lens:\n",
    "        num_lenses_yx = [int(math.sqrt(num_lens)), int(math.sqrt(num_lens))]\n",
    "    else:\n",
    "        print(\"Number of sublens should be a square number\")\n",
    "        assert False\n",
    "\n",
    "    base_microlens_size = min(H // num_lenses_yx[0], W // num_lenses_yx[1]) // 12\n",
    "    microlens_height = int(base_microlens_size * d_lens_sensor)\n",
    "    microlens_height = microlens_height - (\n",
    "        microlens_height % 2\n",
    "    )  # Make dimensions even for convenience\n",
    "    microlens_width = microlens_height  # Keep microlenses square\n",
    "    comap_yx = -np.ones((num_lens, H, W, 2))\n",
    "\n",
    "    if num_lenses_yx[0] > 1:\n",
    "        y_positions = np.linspace(\n",
    "            microlens_height // 2,  # First lens centered at top edge + half lens height\n",
    "            H\n",
    "            - microlens_height\n",
    "            // 2,  # Last lens centered at bottom edge - half lens height\n",
    "            num_lenses_yx[0],\n",
    "        )\n",
    "    else:\n",
    "        y_positions = np.array([H // 2])  # If only one row, place it in the center\n",
    "    if num_lenses_yx[1] > 1:\n",
    "        x_positions = np.linspace(\n",
    "            microlens_width // 2,  # First lens centered at left edge + half lens width\n",
    "            W\n",
    "            - microlens_width\n",
    "            // 2,  # Last lens centered at right edge - half lens width\n",
    "            num_lenses_yx[1],\n",
    "        )\n",
    "    else:\n",
    "        x_positions = np.array([W // 2])  # If only one column, place it in the center\n",
    "\n",
    "    for i in range(num_lens):\n",
    "        row, col = i // num_lenses_yx[1], i % num_lenses_yx[1]\n",
    "        center_y, center_x = int(y_positions[row]), int(x_positions[col])\n",
    "        start_y = int(max(0, center_y - microlens_height // 2))\n",
    "        end_y = int(min(H, center_y + microlens_height // 2))\n",
    "        start_x = int(max(0, center_x - microlens_width // 2))\n",
    "        end_x = int(min(W, center_x + microlens_width // 2))\n",
    "\n",
    "        for y in range(start_y, end_y):\n",
    "            for x in range(start_x, end_x):\n",
    "                local_y, local_x = y - start_y, x - start_x\n",
    "                comap_yx[i, y, x, 0] = local_y\n",
    "                comap_yx[i, y, x, 1] = local_x\n",
    "\n",
    "    # Return the original dimension as second return value\n",
    "    dim_lens_lf_yx = [microlens_height, microlens_width]\n",
    "    return comap_yx, dim_lens_lf_yx\n",
    "\n",
    "\n",
    "def read_images(num_lens, model_path, base):\n",
    "    images = []\n",
    "    for j in range(num_lens):\n",
    "        sub_lens_path = f\"r_{base}_{j}.png\"\n",
    "        im_gt = (\n",
    "            imageio.imread(f\"{model_path}/{sub_lens_path}\").astype(np.float32) / 255.0\n",
    "        )\n",
    "        im_tensor = torch.from_numpy(im_gt[:, :, :3]).permute(2, 0, 1).to(device)\n",
    "        images.append(im_tensor)  # Keep only RGB channels\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "def generate_alpha_map(comap_yx, num_lens, H, W):\n",
    "    overlap_count = np.zeros((H, W), dtype=np.int32)\n",
    "\n",
    "    for i in range(num_lens):\n",
    "        valid_mask = comap_yx[i, :, :, 0] != -1\n",
    "        overlap_count += valid_mask\n",
    "\n",
    "    alpha_map = np.zeros((H, W))\n",
    "    non_zero_mask = overlap_count > 0\n",
    "    alpha_map[non_zero_mask] = 1.0 / overlap_count[non_zero_mask]\n",
    "    return alpha_map\n",
    "\n",
    "\n",
    "def generate_sub_images(\n",
    "    images, comap_yx, dim_lens_lf_yx, num_lens, sensor_size, alpha_map\n",
    "):\n",
    "    \"\"\"\n",
    "    Maps input images to their corresponding locations within each microlens to create\n",
    "    sub-images of the light field using PyTorch operations.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    images : list\n",
    "        List of PyTorch tensors with shape (3, H, W) containing input images.\n",
    "    comap_yx : numpy.ndarray\n",
    "        4D array containing coordinate mapping from get_comap function.\n",
    "    dim_lens_lf_yx : list\n",
    "        Dimensions [height, width] of each microlens.\n",
    "    num_lens : int\n",
    "        Number of microlenses.\n",
    "    sensor_size : int\n",
    "        Size of the output sub-images (both width and height).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    sub_images : list\n",
    "        List of PyTorch tensors with shape (4, sensor_size, sensor_size) containing\n",
    "        the generated sub-images with alpha channel.\n",
    "    \"\"\"\n",
    "    sub_images = []\n",
    "\n",
    "    # Create a mapping from comap_yx index to images index\n",
    "    grid_size = int(np.sqrt(num_lens))\n",
    "    mapping = torch.zeros(num_lens, device=device, dtype=torch.long)\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            comap_idx = i * grid_size + j\n",
    "            images_idx = (grid_size - 1 - i) + (grid_size - 1 - j) * grid_size\n",
    "            mapping[comap_idx] = images_idx\n",
    "\n",
    "    # Resize all images\n",
    "    resized_images = []\n",
    "    for i in range(num_lens):\n",
    "        # Add batch dimension for F.interpolate\n",
    "        img = images[mapping[i]].unsqueeze(0)\n",
    "        # F.interpolate expects (B, C, H, W) format\n",
    "        resized = F.interpolate(\n",
    "            img,\n",
    "            size=(dim_lens_lf_yx[0], dim_lens_lf_yx[1]),\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False,\n",
    "        )\n",
    "        # Remove batch dimension\n",
    "        resized_images.append(resized.squeeze(0))\n",
    "\n",
    "    for i in range(num_lens):\n",
    "        # Create an empty sub-image with 4 channels (RGB + alpha)\n",
    "        sub_image = torch.zeros(\n",
    "            4, sensor_size, sensor_size, device=device, dtype=torch.float32\n",
    "        )\n",
    "\n",
    "        # Get coordinate maps for this microlens\n",
    "        y_coords = comap_yx[i, :, :, 0]\n",
    "        x_coords = comap_yx[i, :, :, 1]\n",
    "\n",
    "        # Create masks for valid coordinates\n",
    "        valid_mask = (y_coords != -1) & (x_coords != -1)\n",
    "        y_in_bounds = (y_coords >= 0) & (y_coords < dim_lens_lf_yx[0])\n",
    "        x_in_bounds = (x_coords >= 0) & (x_coords < dim_lens_lf_yx[1])\n",
    "        valid_mask = valid_mask & y_in_bounds & x_in_bounds\n",
    "\n",
    "        # Get valid pixel indices\n",
    "        y_indices, x_indices = torch.where(valid_mask)\n",
    "\n",
    "        if len(y_indices) > 0:  # Check if there are any valid pixels\n",
    "            # Get corresponding coordinates in the resized image\n",
    "            y_src = y_coords[valid_mask].long()\n",
    "            x_src = x_coords[valid_mask].long()\n",
    "\n",
    "            # Map RGB channels from resized image to sub-image\n",
    "            for c in range(3):\n",
    "                sub_image[c, y_indices, x_indices] = resized_images[i][c, y_src, x_src]\n",
    "\n",
    "            # Set alpha channel\n",
    "            sub_image[3, :, :] = alpha_map\n",
    "\n",
    "        sub_images.append(sub_image)\n",
    "\n",
    "    return sub_images\n",
    "\n",
    "\n",
    "def generate(images, comap_yx, dim_lens_lf_yx, num_lens, sensor_size, alpha_map):\n",
    "    # Compute the grid size (assumes num_lens is a perfect square)\n",
    "    grid_size = int(math.sqrt(num_lens))\n",
    "\n",
    "    # Vectorize the mapping from comap_yx index to images index.\n",
    "    # For each grid coordinate (i, j) in order, the mapping is computed as:\n",
    "    #   mapping[i * grid_size + j] = (grid_size - 1 - i) + (grid_size - 1 - j) * grid_size\n",
    "    idx = torch.arange(grid_size, device=device)\n",
    "    grid_i, grid_j = torch.meshgrid(idx, idx, indexing=\"ij\")\n",
    "    mapping = ((grid_size - 1 - grid_i) + (grid_size - 1 - grid_j) * grid_size).reshape(\n",
    "        -1\n",
    "    )\n",
    "\n",
    "    # Stack images into one tensor and select the images as ordered by the mapping.\n",
    "    # images_tensor shape: (N, 3, H, W) --> selected_images shape: (num_lens, 3, H, W)\n",
    "    images_tensor = torch.stack(images, dim=0).to(device)\n",
    "    selected_images = images_tensor[mapping]\n",
    "\n",
    "    # Resize all selected images at once using vectorized interpolation.\n",
    "    # The output shape will be (num_lens, 3, lens_H, lens_W)\n",
    "    resized_images = F.interpolate(\n",
    "        selected_images,\n",
    "        size=(dim_lens_lf_yx[0], dim_lens_lf_yx[1]),\n",
    "        mode=\"bilinear\",\n",
    "        align_corners=False,\n",
    "    )\n",
    "\n",
    "    output_image = torch.zeros(\n",
    "        3, sensor_size, sensor_size, device=device, dtype=torch.float32\n",
    "    )\n",
    "\n",
    "    # Loop over each microlens and accumulate its contribution.\n",
    "    for i in range(num_lens):\n",
    "        # Extract the coordinate maps for this microlens (each of shape (sensor_size, sensor_size)).\n",
    "        # The last dimension in comap_yx_torch holds [y, x] coordinates.\n",
    "        y_coords = comap_yx[i, :, :, 0]\n",
    "        x_coords = comap_yx[i, :, :, 1]\n",
    "\n",
    "        # Build a mask that marks valid pixel positions:\n",
    "        # - Coordinates must not equal -1\n",
    "        # - Must be within the bounds of the resized image dimensions.\n",
    "        valid_mask = (\n",
    "            (y_coords != -1)\n",
    "            & (x_coords != -1)\n",
    "            & (y_coords >= 0)\n",
    "            & (y_coords < dim_lens_lf_yx[0])\n",
    "            & (x_coords >= 0)\n",
    "            & (x_coords < dim_lens_lf_yx[1])\n",
    "        )\n",
    "\n",
    "        # Only process this microlens if there are any valid mapping positions.\n",
    "        if valid_mask.any():\n",
    "            # Get 2D indices within the sub-image where valid_mask is True.\n",
    "            y_indices, x_indices = torch.where(valid_mask)\n",
    "\n",
    "            y_src = y_coords[valid_mask].long()\n",
    "            x_src = x_coords[valid_mask].long()\n",
    "\n",
    "            output_image[:, y_indices, x_indices] += resized_images[\n",
    "                i, :, y_src, x_src\n",
    "            ] * alpha_map[y_indices, x_indices].unsqueeze(0)\n",
    "\n",
    "    # Clamp the final output to ensure pixel values are in the valid range [0, 1].\n",
    "    output_image = torch.clamp(output_image, 0, 1)\n",
    "\n",
    "    return output_image\n",
    "\n",
    "\n",
    "# def generate(images, comap_yx, dim_lens_lf_yx, num_lens, sensor_size, alpha_map):\n",
    "#     grid_size = int(math.sqrt(num_lens))\n",
    "#     idx = torch.arange(grid_size, device=device)\n",
    "#     grid_i, grid_j = torch.meshgrid(idx, idx, indexing='ij')\n",
    "#     mapping = ((grid_size - 1 - grid_i) + (grid_size - 1 - grid_j) * grid_size).reshape(-1)\n",
    "\n",
    "#     images_tensor = torch.stack(images, dim=0).to(device)\n",
    "#     selected_images = images_tensor[mapping]\n",
    "#     resized_images = F.interpolate(\n",
    "#         selected_images,\n",
    "#         size=(dim_lens_lf_yx[0], dim_lens_lf_yx[1]),\n",
    "#         mode='bilinear',\n",
    "#         align_corners=False\n",
    "#     )\n",
    "\n",
    "#     output_image = torch.zeros(3, sensor_size, sensor_size, device=device, dtype=torch.float32)\n",
    "\n",
    "#     for i in range(num_lens):\n",
    "#         y_coords = comap_yx[i, :, :, 0]\n",
    "#         x_coords = comap_yx[i, :, :, 1]\n",
    "\n",
    "#         valid_mask = (y_coords != -1) & (x_coords != -1) & \\\n",
    "#                      (y_coords >= 0) & (y_coords < dim_lens_lf_yx[0]) & \\\n",
    "#                      (x_coords >= 0) & (x_coords < dim_lens_lf_yx[1])\n",
    "\n",
    "#         # Only process this microlens if there are any valid mapping positions.\n",
    "#         if valid_mask.any():\n",
    "#             # Get 2D indices within the sub-image where valid_mask is True.\n",
    "#             y_indices, x_indices = torch.where(valid_mask)\n",
    "#             y_src = y_coords[valid_mask].long()\n",
    "#             x_src = x_coords[valid_mask].long()\n",
    "#             output_image[:, y_indices, x_indices] += resized_images[i, :, y_src, x_src] * alpha_map[y_indices, x_indices].unsqueeze(0)\n",
    "\n",
    "#     # Clamp the final output to ensure pixel values are in the valid range [0, 1].\n",
    "#     output_image = torch.clamp(output_image, 0, 1)\n",
    "\n",
    "#     return output_image\n",
    "\n",
    "mode_path = \"/home/wl757/multiplexed-pixels/plenoxels/blender_data/lego_gen12/train_multilens_16_black\"\n",
    "base = \"59\"\n",
    "NUM_LENS = 16\n",
    "SENSOR_SIZE = 800\n",
    "d_lens_sensor = 20  # this is the value to change for more or less multiplexing\n",
    "\n",
    "comap_yx, dim_lens_lf_yx = get_comap(NUM_LENS, d_lens_sensor, SENSOR_SIZE, SENSOR_SIZE)\n",
    "alpha_map = (\n",
    "    torch.from_numpy(generate_alpha_map(comap_yx, NUM_LENS, SENSOR_SIZE, SENSOR_SIZE))\n",
    "    .float()\n",
    "    .to(device)\n",
    ")\n",
    "plt.imshow(alpha_map.cpu().numpy())\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "comap_yx = torch.from_numpy(comap_yx).to(device)\n",
    "images = read_images(NUM_LENS, model_path, base)\n",
    "# multiplexed_image = generate(images, comap_yx, dim_lens_lf_yx, NUM_LENS, SENSOR_SIZE, alpha_map)\n",
    "sub_images = generate_sub_images(\n",
    "    images, comap_yx, dim_lens_lf_yx, NUM_LENS, SENSOR_SIZE, alpha_map\n",
    ")\n",
    "for sub_image in sub_images:\n",
    "    rgb = sub_image[:3]\n",
    "    alpha = sub_image[3]\n",
    "    plt.imshow((rgb * alpha).cpu().numpy().transpose(1, 2, 0))\n",
    "    plt.show()\n",
    "# plt.imshow(sub_images[5].cpu().numpy().transpose(1, 2, 0))\n",
    "# plt.show()\n",
    "# output_image = torch.zeros(3, SENSOR_SIZE, SENSOR_SIZE, device=device, dtype=torch.float32)\n",
    "# for sub_image in sub_images[5:7]:\n",
    "#     rgb = sub_image[:3]\n",
    "#     alpha = sub_image[3]\n",
    "#     output_image += rgb * alpha\n",
    "# output_image = torch.clamp(output_image, 0, 1)\n",
    "# plt.imshow(output_image.cpu().numpy().transpose(1, 2, 0))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9193eda9-f6c1-40f8-b9aa-f04c0b7a4624",
   "metadata": {},
   "source": [
    "Calculated how the maximum number of rays from microlens that maps to one sensor pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2ac372-93bc-46e7-98bc-192fa0df7a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PER_PIXEL = 20\n",
    "NUM_LENS = num_lenses_yx[0] * num_lenses_yx[1]\n",
    "sensor_size = 800\n",
    "\n",
    "\n",
    "def get_rays_per_pixel(H, W, comap_yx):\n",
    "    per_pixel = np.zeros((sensor_size, sensor_size, MAX_PER_PIXEL, 3)).astype(np.uint32)\n",
    "    mask = np.zeros((sensor_size, sensor_size, MAX_PER_PIXEL)).astype(float)\n",
    "    cnt = np.zeros((sensor_size, sensor_size)).astype(np.uint8)\n",
    "    for a in range(sensor_size):\n",
    "        for b in range(sensor_size):\n",
    "            for l in range(NUM_LENS):\n",
    "                x = comap_yx[l, b, a, 1]\n",
    "                y = comap_yx[l, b, a, 0]\n",
    "                if x != -1 and y != -1:\n",
    "                    per_pixel[a, b, cnt[a, b]] = np.array([x, y, l])\n",
    "                    mask[a, b, cnt[a, b]] = 1.0\n",
    "                    cnt[a, b] += 1\n",
    "    return per_pixel, mask, cnt\n",
    "\n",
    "\n",
    "per_pixel, mask, cnt = get_rays_per_pixel(sensor_size, sensor_size, comap_yx)\n",
    "MAX_PER_PIXEL = np.max(cnt)\n",
    "print(\"MAX_PER_PIXEL:\", MAX_PER_PIXEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bca33b-74c6-4593-822e-581cfd526891",
   "metadata": {},
   "source": [
    "Generate multiplexed images, set dir_name to be the saved directory of multiplexed images, and set selected_views to be a list of view index from transform_train.json, set rendered_views_path to be the directory that contains images from the sublens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d66eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "import os\n",
    "import json\n",
    "\n",
    "num_lenses_yx = [4, 4]  # [10,10] #[2,1] #[1,1]# [4,4] #[1,1]# [4,4]\n",
    "MAX_PER_PIXEL = 20\n",
    "NUM_LENS = num_lenses_yx[0] * num_lenses_yx[1]\n",
    "sensor_size = 800\n",
    "d_lens_sensor = 20  # this is the value to change for more or less multiplexing\n",
    "\n",
    "\n",
    "def get_comap(num_lens, d_lens_sensor, H, W):\n",
    "    # Verify input and calculate the grid dimensions\n",
    "    if math.sqrt(num_lens) ** 2 == num_lens:\n",
    "        num_lenses_yx = [int(math.sqrt(num_lens)), int(math.sqrt(num_lens))]\n",
    "    else:\n",
    "        print(\"Number of sublens should be a square number\")\n",
    "        assert False\n",
    "\n",
    "    # Calculate microlens dimensions in pixels based on d_lens_sensor\n",
    "    base_microlens_size = min(H // num_lenses_yx[0], W // num_lenses_yx[1]) // 12\n",
    "    microlens_height = int(base_microlens_size * d_lens_sensor)\n",
    "    microlens_height = microlens_height - (\n",
    "        microlens_height % 2\n",
    "    )  # Make dimensions even for convenience\n",
    "    microlens_width = microlens_height  # Keep microlenses square\n",
    "    comap_yx = -np.ones((num_lens, H, W, 2))\n",
    "\n",
    "    # Calculate positions for microlenses to distribute from edge to edge\n",
    "    if num_lenses_yx[0] > 1:\n",
    "        y_positions = np.linspace(\n",
    "            microlens_height // 2,  # First lens centered at top edge + half lens height\n",
    "            H\n",
    "            - microlens_height\n",
    "            // 2,  # Last lens centered at bottom edge - half lens height\n",
    "            num_lenses_yx[0],\n",
    "        )\n",
    "    else:\n",
    "        y_positions = np.array([H // 2])  # If only one row, place it in the center\n",
    "    if num_lenses_yx[1] > 1:\n",
    "        x_positions = np.linspace(\n",
    "            microlens_width // 2,  # First lens centered at left edge + half lens width\n",
    "            W\n",
    "            - microlens_width\n",
    "            // 2,  # Last lens centered at right edge - half lens width\n",
    "            num_lenses_yx[1],\n",
    "        )\n",
    "    else:\n",
    "        x_positions = np.array([W // 2])  # If only one column, place it in the center\n",
    "\n",
    "    for i in range(num_lens):\n",
    "        row, col = i // num_lenses_yx[1], i % num_lenses_yx[1]\n",
    "        center_y, center_x = int(y_positions[row]), int(x_positions[col])\n",
    "        start_y = int(max(0, center_y - microlens_height // 2))\n",
    "        end_y = int(min(H, center_y + microlens_height // 2))\n",
    "        start_x = int(max(0, center_x - microlens_width // 2))\n",
    "        end_x = int(min(W, center_x + microlens_width // 2))\n",
    "\n",
    "        for y in range(start_y, end_y):\n",
    "            for x in range(start_x, end_x):\n",
    "                local_y, local_x = y - start_y, x - start_x\n",
    "                comap_yx[i, y, x, 0] = local_y\n",
    "                comap_yx[i, y, x, 1] = local_x\n",
    "\n",
    "    # Return the original dimension as second return value\n",
    "    dim_lens_lf_yx = [microlens_height, microlens_width]\n",
    "    return comap_yx, dim_lens_lf_yx\n",
    "\n",
    "\n",
    "comap_yx, _ = get_comap(16, 20, 800, 800)\n",
    "print(comap_yx.max())\n",
    "plt.imshow(comap_yx[0, :, :, 0])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.imshow(comap_yx[3, :, :, 1])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5450c75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "num_lenses_yx = [4, 4]  # [10,10] #[2,1] #[1,1]# [4,4] #[1,1]# [4,4]\n",
    "MAX_PER_PIXEL = 20\n",
    "NUM_LENS = num_lenses_yx[0] * num_lenses_yx[1]\n",
    "sensor_size = 800\n",
    "d_lens_sensor = 10  # this is the value to change for more or less multiplexing\n",
    "\n",
    "model_path = \"/home/wl757/multiplexed-pixels/plenoxels/blender_data/lego_gen12/train_multilens_16_black\"\n",
    "SUBIMAGES = [x for x in range(16)]\n",
    "\n",
    "\n",
    "def get_comap(num_lens, d_lens_sensor, H, W):\n",
    "    dim_yx = [H, W]\n",
    "    dx = 0.020  # pixel size in mm\n",
    "    if math.sqrt(num_lens) ** 2 == num_lens:\n",
    "        num_lenses_yx = [int(math.sqrt(num_lens)), int(math.sqrt(num_lens))]\n",
    "    else:\n",
    "        print(\"Number of sublens should be a square number\")\n",
    "        assert False\n",
    "\n",
    "    d_lens_sensor_lf = 10  # distance between lens array and sensor when no multiplexing (lightfield), in mm\n",
    "    dim_lens_lf_yx = [\n",
    "        dim_yx[0] // num_lenses_yx[0],\n",
    "        dim_yx[0] // num_lenses_yx[0],\n",
    "    ]  # number of pixels corresponding to a microlens at the lightfield situation\n",
    "    d_lenses = (\n",
    "        dim_lens_lf_yx[0] * dx\n",
    "    )  # # distance between the centers of adjacent microlenses, in mm\n",
    "\n",
    "    # d_lens_sensor = FLAGS.d_lens_sensor  # this is the value to change for more or less multiplexing\n",
    "\n",
    "    # print(f'd_lenses {d_lenses}, dim_lens_lf_yx {dim_lens_lf_yx}, d_lens_sensor {d_lens_sensor}')\n",
    "\n",
    "    lenses_loc_yx = np.meshgrid(\n",
    "        (np.arange(num_lenses_yx[0]) - (num_lenses_yx[0] - 1) / 2) * d_lenses,\n",
    "        (np.arange(num_lenses_yx[1]) - (num_lenses_yx[1] - 1) / 2) * d_lenses,\n",
    "        indexing=\"ij\",\n",
    "    )\n",
    "    lenses_loc_yx = (\n",
    "        np.array(lenses_loc_yx).reshape(2, np.prod(num_lenses_yx)).transpose()\n",
    "    )\n",
    "\n",
    "    dim_lens_yx = [\n",
    "        dim_lens_lf_yx[0] / d_lens_sensor_lf * d_lens_sensor,\n",
    "        dim_lens_lf_yx[1] / d_lens_sensor_lf * d_lens_sensor,\n",
    "    ]\n",
    "    dim_lens_yx = [\n",
    "        dim_lens_yx[0] - dim_lens_yx[0] % 2,\n",
    "        dim_lens_yx[1] - dim_lens_yx[1] % 2,\n",
    "    ]  # assuming dim_lens_yx is even\n",
    "    lens_sensor_ind_yx = np.array(\n",
    "        np.meshgrid(np.arange(dim_lens_yx[0]), np.arange(dim_lens_yx[1]), indexing=\"ij\")\n",
    "    ).transpose((1, 2, 0))\n",
    "\n",
    "    sensor_pixel_loc_y = (np.arange(dim_yx[0]) - dim_yx[0] / 2) * dx\n",
    "    sensor_pixel_loc_x = (np.arange(dim_yx[1]) - dim_yx[1] / 2) * dx\n",
    "\n",
    "    comap_yx = -np.ones((len(lenses_loc_yx), dim_yx[0], dim_yx[1], 2))\n",
    "\n",
    "    for i, lens_loc_yx in enumerate(lenses_loc_yx):\n",
    "        center_index_yx = [\n",
    "            np.argmin(np.abs(lens_loc_yx[0] - sensor_pixel_loc_y)),\n",
    "            np.argmin(np.abs(lens_loc_yx[1] - sensor_pixel_loc_x)),\n",
    "        ]\n",
    "        start_index_sensor_yx = [\n",
    "            np.maximum(0, center_index_yx[0] - dim_lens_yx[0] // 2).astype(int),\n",
    "            np.maximum(0, center_index_yx[1] - dim_lens_yx[1] // 2).astype(int),\n",
    "        ]\n",
    "        end_index_sensor_yx = [\n",
    "            np.minimum(dim_yx[0], center_index_yx[0] + dim_lens_yx[0] // 2).astype(int),\n",
    "            np.minimum(dim_yx[1], center_index_yx[1] + dim_lens_yx[1] // 2).astype(int),\n",
    "        ]\n",
    "\n",
    "        start_index_lens_yx = [\n",
    "            int(dim_lens_yx[0] // 2 - center_index_yx[0] + start_index_sensor_yx[0]),\n",
    "            int(dim_lens_yx[1] // 2 - center_index_yx[1] + start_index_sensor_yx[1]),\n",
    "        ]\n",
    "        end_index_lens_yx = [\n",
    "            int(dim_lens_yx[0] // 2 - center_index_yx[0] + end_index_sensor_yx[0]),\n",
    "            int(dim_lens_yx[1] // 2 - center_index_yx[1] + end_index_sensor_yx[1]),\n",
    "        ]\n",
    "\n",
    "        comap_yx[\n",
    "            i,\n",
    "            start_index_sensor_yx[0] : end_index_sensor_yx[0],\n",
    "            start_index_sensor_yx[1] : end_index_sensor_yx[1],\n",
    "            :,\n",
    "        ] = lens_sensor_ind_yx[\n",
    "            start_index_lens_yx[0] : end_index_lens_yx[0],\n",
    "            start_index_lens_yx[1] : end_index_lens_yx[1],\n",
    "            :,\n",
    "        ]\n",
    "    return comap_yx, dim_lens_lf_yx\n",
    "\n",
    "\n",
    "def get_rays_per_pixel(H, W, comap_yx, max_per_pixel, num_lens):\n",
    "    MAX_PER_PIXEL_INIT = 20\n",
    "    # per_pixel = torch.zeros((H,W,max_per_pixel,3), dtype=torch.int)\n",
    "    # mask = torch.zeros((H,W,max_per_pixel), dtype=torch.int)\n",
    "    # cnt_mpp = torch.zeros((H,W), dtype=torch.int)\n",
    "\n",
    "    per_pixel = np.zeros((W, H, max_per_pixel, 3)).astype(int)\n",
    "    mask = np.zeros((W, H, max_per_pixel)).astype(int)\n",
    "    cnt_mpp = np.zeros((W, H)).astype(int)\n",
    "\n",
    "    # per_pixel = (comap_yx != -1).nonzero(as_tuple=True) #number_of_matches x tensor_dimension\n",
    "    # print(H, W)\n",
    "    for l in range(num_lens):\n",
    "        for a in range(W):\n",
    "            for b in range(H):\n",
    "                x = comap_yx[l, b, a, 1]\n",
    "                y = comap_yx[l, b, a, 0]\n",
    "                if x != -1 and y != -1:\n",
    "                    per_pixel[a, b, cnt_mpp[a, b]] = np.array([x, y, l])\n",
    "                    mask[a, b, cnt_mpp[a, b]] = 1.0\n",
    "                    cnt_mpp[a, b] += 1\n",
    "    return per_pixel, mask, cnt_mpp\n",
    "\n",
    "\n",
    "def generate(comap_yx, base, model_path, num_lens, H, W):\n",
    "    rendered_views_path = model_path\n",
    "\n",
    "    maps_pixel_to_rays, mask, cnt_mpp = get_rays_per_pixel(H, W, comap_yx, 20, num_lens)\n",
    "    MAX_PER_PIXEL = np.max(cnt_mpp)\n",
    "    maps_pixel_to_rays, mask, cnt_mpp = get_rays_per_pixel(\n",
    "        H, W, comap_yx, MAX_PER_PIXEL, num_lens\n",
    "    )\n",
    "    u = int(np.max(comap_yx[0, :, :, :], axis=(0, 1, 2)) + 1)\n",
    "    sub_lens = np.zeros((num_lens, u, u, 3))\n",
    "\n",
    "    for j in range(num_lens):\n",
    "        sub_lens_path = f\"r_{base}_{j}.png\"\n",
    "        im_gt = (\n",
    "            imageio.imread(f\"{rendered_views_path}/{sub_lens_path}\").astype(np.float32)\n",
    "            / 255.0\n",
    "        )\n",
    "\n",
    "        a = int(np.max(comap_yx[0, :, :, :], axis=(0, 1, 2))) + 1\n",
    "        im_gt = resize(im_gt, (a, a), anti_aliasing=True)\n",
    "        sub_lens[j, :, :, :] = im_gt[:, :, :3]\n",
    "\n",
    "    rgb = np.zeros((H, W, 3)).astype(float)\n",
    "    cnt_subpixels = np.zeros((H, W), dtype=int)\n",
    "\n",
    "    for i_index in range(H):\n",
    "        for j_index in range(W):\n",
    "            for cnt_rays in range(maps_pixel_to_rays.shape[2]):  # over MAX_PER_PIXEL\n",
    "                x_index = maps_pixel_to_rays[i_index, j_index, cnt_rays, 0]  # height\n",
    "                y_index = maps_pixel_to_rays[i_index, j_index, cnt_rays, 1]  # width\n",
    "                l_index = maps_pixel_to_rays[i_index, j_index, cnt_rays, 2]  # lens\n",
    "                if mask[i_index, j_index, cnt_rays] == 1 and l_index in range(num_lens):\n",
    "                    rgb[i_index, j_index] += sub_lens[l_index, x_index, y_index, :]\n",
    "                    cnt_subpixels[i_index, j_index] += 1\n",
    "            # rgb[i_index,j_index] = rgb[i_index,j_index] / cnt_subpixels[i_index, j_index] +1e-9#MAX_PER_PIXEL\n",
    "    print(f\"MAX VALUE {np.max(rgb)}\")\n",
    "    max_pixel = np.max(rgb)\n",
    "    rgb2 = rgb  # /np.max(rgb)\n",
    "    # vis = np.asarray(rgb2 * 255).astype(np.uint8)\n",
    "    rgb = np.concatenate((rgb2, np.ones((H, W, 1))), axis=2)\n",
    "    im = Image.fromarray(np.uint8(rgb * 255))\n",
    "    return rgb, max_pixel\n",
    "\n",
    "\n",
    "comap_yx, _ = get_comap(NUM_LENS, d_lens_sensor, sensor_size, sensor_size)\n",
    "plt.imshow(comap_yx[0, :, :, 1])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "print(comap_yx.shape)\n",
    "rgb, _ = generate(\n",
    "    comap_yx,\n",
    "    \"59\",\n",
    "    model_path=model_path,\n",
    "    num_lens=NUM_LENS,\n",
    "    H=sensor_size,\n",
    "    W=sensor_size,\n",
    ")\n",
    "print(rgb.shape)\n",
    "plt.imshow(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c66b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "num_lenses_yx = [4, 4]  # [10,10] #[2,1] #[1,1]# [4,4] #[1,1]# [4,4]\n",
    "MAX_PER_PIXEL = 20\n",
    "NUM_LENS = num_lenses_yx[0] * num_lenses_yx[1]\n",
    "sensor_size = 800\n",
    "d_lens_sensor = 15  # this is the value to change for more or less multiplexing\n",
    "\n",
    "model_path = \"/home/wl757/multiplexed-pixels/plenoxels/blender_data/lego_gen12/train_multilens_16_black\"\n",
    "SUBIMAGES = [x for x in range(16)]\n",
    "\n",
    "\n",
    "def get_comap(num_lens, d_lens_sensor, H, W):\n",
    "    \"\"\"\n",
    "    Computes a mapping from sensor pixels to lens subimage pixels.\n",
    "    For each lens, if its intended subimage (given by d_lens_sensor)\n",
    "    would extend outside the sensor boundaries, we clip the sensor region\n",
    "    and proportionally reduce the corresponding lens region.\n",
    "    \"\"\"\n",
    "    # Sensor dimensions and pixel size (in mm)\n",
    "    dim_yx = [H, W]\n",
    "    dx = 0.020\n",
    "\n",
    "    # Ensure the total number of lenses is a square number.\n",
    "    if math.sqrt(num_lens) ** 2 == num_lens:\n",
    "        num_lenses_yx = [int(math.sqrt(num_lens)), int(math.sqrt(num_lens))]\n",
    "    else:\n",
    "        raise ValueError(\"Number of sublens should be a square number\")\n",
    "\n",
    "    # Parameters for the lightfield situation\n",
    "    d_lens_sensor_lf = 10  # baseline distance (mm) between lens array and sensor\n",
    "    # For lightfield, each microlens covers a subset of sensor pixels:\n",
    "    dim_lens_lf_yx = [dim_yx[0] // num_lenses_yx[0], dim_yx[0] // num_lenses_yx[0]]\n",
    "    d_lenses = dim_lens_lf_yx[0] * dx  # center-to-center spacing in mm\n",
    "\n",
    "    # Compute the (x,y) positions of microlens centers (in mm)\n",
    "    lenses_loc_yx = np.meshgrid(\n",
    "        (np.arange(num_lenses_yx[0]) - (num_lenses_yx[0] - 1) / 2) * d_lenses,\n",
    "        (np.arange(num_lenses_yx[1]) - (num_lenses_yx[1] - 1) / 2) * d_lenses,\n",
    "        indexing=\"ij\",\n",
    "    )\n",
    "    lenses_loc_yx = np.array(lenses_loc_yx).reshape(2, -1).T\n",
    "\n",
    "    # Intended size (in pixels) for each lens's contribution AFTER multiplexing.\n",
    "    # This is scaled from the lightfield case using d_lens_sensor.\n",
    "    dim_lens_yx = [\n",
    "        dim_lens_lf_yx[0] / d_lens_sensor_lf * d_lens_sensor,\n",
    "        dim_lens_lf_yx[1] / d_lens_sensor_lf * d_lens_sensor,\n",
    "    ]\n",
    "    # Force an even number of pixels\n",
    "    dim_lens_yx = [\n",
    "        dim_lens_yx[0] - dim_lens_yx[0] % 2,\n",
    "        dim_lens_yx[1] - dim_lens_yx[1] % 2,\n",
    "    ]\n",
    "\n",
    "    # Create the full grid of indices for a microlens subimage.\n",
    "    lens_sensor_ind_yx = np.array(\n",
    "        np.meshgrid(\n",
    "            np.arange(int(dim_lens_yx[0])),\n",
    "            np.arange(int(dim_lens_yx[1])),\n",
    "            indexing=\"ij\",\n",
    "        )\n",
    "    ).transpose((1, 2, 0))\n",
    "\n",
    "    # Compute sensor pixel coordinates (in mm, centered)\n",
    "    sensor_pixel_loc_y = (np.arange(dim_yx[0]) - dim_yx[0] / 2) * dx\n",
    "    sensor_pixel_loc_x = (np.arange(dim_yx[1]) - dim_yx[1] / 2) * dx\n",
    "\n",
    "    # Initialize the mapping with -1 (which indicates no contribution)\n",
    "    comap_yx = -np.ones((len(lenses_loc_yx), dim_yx[0], dim_yx[1], 2))\n",
    "\n",
    "    # For each lens, compute its mapping while ensuring full containment on the sensor.\n",
    "    for i, lens_loc in enumerate(lenses_loc_yx):\n",
    "        # Find the sensor pixel closest to the microlens center (in y and x)\n",
    "        center_index_y = np.argmin(np.abs(lens_loc[0] - sensor_pixel_loc_y))\n",
    "        center_index_x = np.argmin(np.abs(lens_loc[1] - sensor_pixel_loc_x))\n",
    "\n",
    "        # Intended half-size of the lens contribution (in pixels)\n",
    "        half_dim_y = int(dim_lens_yx[0] // 2)\n",
    "        half_dim_x = int(dim_lens_yx[1] // 2)\n",
    "\n",
    "        # Compute intended sensor region (which may extend beyond sensor bounds)\n",
    "        sensor_start_y = center_index_y - half_dim_y\n",
    "        sensor_end_y = center_index_y + half_dim_y\n",
    "        sensor_start_x = center_index_x - half_dim_x\n",
    "        sensor_end_x = center_index_x + half_dim_x\n",
    "\n",
    "        # Clip the sensor region to fall within the sensor boundaries.\n",
    "        effective_sensor_start_y = max(sensor_start_y, 0)\n",
    "        effective_sensor_end_y = min(sensor_end_y, dim_yx[0])\n",
    "        effective_sensor_start_x = max(sensor_start_x, 0)\n",
    "        effective_sensor_end_x = min(sensor_end_x, dim_yx[1])\n",
    "\n",
    "        # The actual sensor region size available for this lens:\n",
    "        sensor_region_height = effective_sensor_end_y - effective_sensor_start_y\n",
    "        sensor_region_width = effective_sensor_end_x - effective_sensor_start_x\n",
    "\n",
    "        # Compute the size of the “intended” region (might be larger than actual if clamped).\n",
    "        intended_region_height = sensor_end_y - sensor_start_y\n",
    "        intended_region_width = sensor_end_x - sensor_start_x\n",
    "\n",
    "        # Determine scaling factors between the intended full lens subimage (dim_lens_yx)\n",
    "        # and the intended sensor region.\n",
    "        scale_y = (\n",
    "            dim_lens_yx[0] / intended_region_height if intended_region_height > 0 else 1\n",
    "        )\n",
    "        scale_x = (\n",
    "            dim_lens_yx[1] / intended_region_width if intended_region_width > 0 else 1\n",
    "        )\n",
    "\n",
    "        # Determine the offset (in sensor pixels) caused by clipping.\n",
    "        offset_y = effective_sensor_start_y - sensor_start_y\n",
    "        offset_x = effective_sensor_start_x - sensor_start_x\n",
    "\n",
    "        # Map to the corresponding region in the lens subimage.\n",
    "        lens_start_y = int(offset_y * scale_y)\n",
    "        lens_start_x = int(offset_x * scale_x)\n",
    "        lens_region_height = int(sensor_region_height * scale_y)\n",
    "        lens_region_width = int(sensor_region_width * scale_x)\n",
    "        lens_end_y = lens_start_y + lens_region_height\n",
    "        lens_end_x = lens_start_x + lens_region_width\n",
    "\n",
    "        # Clamp lens indices in case of rounding issues.\n",
    "        lens_start_y = max(lens_start_y, 0)\n",
    "        lens_start_x = max(lens_start_x, 0)\n",
    "        lens_end_y = min(lens_end_y, int(dim_lens_yx[0]))\n",
    "        lens_end_x = min(lens_end_x, int(dim_lens_yx[1]))\n",
    "\n",
    "        # (Optional) Adjust if the regions have different sizes\n",
    "        sensor_region_actual = (\n",
    "            effective_sensor_end_y - effective_sensor_start_y,\n",
    "            effective_sensor_end_x - effective_sensor_start_x,\n",
    "        )\n",
    "        lens_region_actual = (lens_end_y - lens_start_y, lens_end_x - lens_start_x)\n",
    "        if sensor_region_actual != lens_region_actual:\n",
    "            min_height = min(sensor_region_actual[0], lens_region_actual[0])\n",
    "            min_width = min(sensor_region_actual[1], lens_region_actual[1])\n",
    "            effective_sensor_end_y = effective_sensor_start_y + min_height\n",
    "            effective_sensor_end_x = effective_sensor_start_x + min_width\n",
    "            lens_end_y = lens_start_y + min_height\n",
    "            lens_end_x = lens_start_x + min_width\n",
    "\n",
    "        # Assign the mapping for this lens:\n",
    "        comap_yx[\n",
    "            i,\n",
    "            effective_sensor_start_y:effective_sensor_end_y,\n",
    "            effective_sensor_start_x:effective_sensor_end_x,\n",
    "            :,\n",
    "        ] = lens_sensor_ind_yx[lens_start_y:lens_end_y, lens_start_x:lens_end_x, :]\n",
    "\n",
    "    return comap_yx, dim_lens_lf_yx\n",
    "\n",
    "\n",
    "def get_rays_per_pixel(H, W, comap_yx, max_per_pixel, num_lens):\n",
    "    MAX_PER_PIXEL_INIT = 20\n",
    "    # per_pixel = torch.zeros((H,W,max_per_pixel,3), dtype=torch.int)\n",
    "    # mask = torch.zeros((H,W,max_per_pixel), dtype=torch.int)\n",
    "    # cnt_mpp = torch.zeros((H,W), dtype=torch.int)\n",
    "\n",
    "    per_pixel = np.zeros((W, H, max_per_pixel, 3)).astype(int)\n",
    "    mask = np.zeros((W, H, max_per_pixel)).astype(int)\n",
    "    cnt_mpp = np.zeros((W, H)).astype(int)\n",
    "\n",
    "    # per_pixel = (comap_yx != -1).nonzero(as_tuple=True) #number_of_matches x tensor_dimension\n",
    "    # print(H, W)\n",
    "    for l in range(num_lens):\n",
    "        for a in range(W):\n",
    "            for b in range(H):\n",
    "                x = comap_yx[l, b, a, 1]\n",
    "                y = comap_yx[l, b, a, 0]\n",
    "                if x != -1 and y != -1:\n",
    "                    per_pixel[a, b, cnt_mpp[a, b]] = np.array([x, y, l])\n",
    "                    mask[a, b, cnt_mpp[a, b]] = 1.0\n",
    "                    cnt_mpp[a, b] += 1\n",
    "    return per_pixel, mask, cnt_mpp\n",
    "\n",
    "\n",
    "def generate(comap_yx, base, model_path, num_lens, H, W):\n",
    "    #     rendered_views_path = '/home/vitran/plenoxels/jax_logs10/original2/multilens16_5img_5679_and59'\n",
    "    # rendered_views_path = model_path +'/train_multilens_16_black'#+ \"/multiplexed_input\"\n",
    "    rendered_views_path = model_path  # +'/train_grid_att2'#+ \"/multiplexed_input\"\n",
    "\n",
    "    maps_pixel_to_rays, mask, cnt_mpp = get_rays_per_pixel(H, W, comap_yx, 20, num_lens)\n",
    "    MAX_PER_PIXEL = np.max(cnt_mpp)\n",
    "    maps_pixel_to_rays, mask, cnt_mpp = get_rays_per_pixel(\n",
    "        H, W, comap_yx, MAX_PER_PIXEL, num_lens\n",
    "    )\n",
    "    u = int(np.max(comap_yx[0, :, :, :], axis=(0, 1, 2)) + 1)\n",
    "    sub_lens = np.zeros((num_lens, u, u, 3))\n",
    "\n",
    "    for j in range(num_lens):\n",
    "        sub_lens_path = f\"r_{base}_{j}.png\"\n",
    "        im_gt = (\n",
    "            imageio.imread(f\"{rendered_views_path}/{sub_lens_path}\").astype(np.float32)\n",
    "            / 255.0\n",
    "        )\n",
    "\n",
    "        a = int(np.max(comap_yx[0, :, :, :], axis=(0, 1, 2))) + 1\n",
    "        im_gt = resize(im_gt, (a, a), anti_aliasing=True)\n",
    "        sub_lens[j, :, :, :] = im_gt[:, :, :3]\n",
    "\n",
    "    rgb = np.zeros((H, W, 3)).astype(float)\n",
    "    cnt_subpixels = np.zeros((H, W), dtype=int)\n",
    "\n",
    "    for i_index in range(H):\n",
    "        for j_index in range(W):\n",
    "            for cnt_rays in range(maps_pixel_to_rays.shape[2]):  # over MAX_PER_PIXEL\n",
    "                x_index = maps_pixel_to_rays[i_index, j_index, cnt_rays, 0]  # height\n",
    "                y_index = maps_pixel_to_rays[i_index, j_index, cnt_rays, 1]  # width\n",
    "                l_index = maps_pixel_to_rays[i_index, j_index, cnt_rays, 2]  # lens\n",
    "                if mask[i_index, j_index, cnt_rays] == 1 and l_index in SUBIMAGES:\n",
    "                    rgb[i_index, j_index] += sub_lens[l_index, x_index, y_index, :]\n",
    "                    cnt_subpixels[i_index, j_index] += 1\n",
    "            # rgb[i_index,j_index] = rgb[i_index,j_index] / cnt_subpixels[i_index, j_index] +1e-9#MAX_PER_PIXEL\n",
    "    print(f\"MAX VALUE {np.max(rgb)}\")\n",
    "    max_pixel = np.max(rgb)\n",
    "    rgb2 = rgb  # /np.max(rgb)\n",
    "    # vis = np.asarray(rgb2 * 255).astype(np.uint8)\n",
    "    rgb = np.concatenate((rgb2, np.ones((H, W, 1))), axis=2)\n",
    "    im = Image.fromarray(np.uint8(rgb * 255))\n",
    "    return rgb, max_pixel\n",
    "\n",
    "\n",
    "comap_yx, _ = get_comap(NUM_LENS, d_lens_sensor, sensor_size, sensor_size)\n",
    "rgb, _ = generate(\n",
    "    comap_yx,\n",
    "    \"59\",\n",
    "    model_path=model_path,\n",
    "    num_lens=NUM_LENS,\n",
    "    H=sensor_size,\n",
    "    W=sensor_size,\n",
    ")\n",
    "print(rgb.shape)\n",
    "plt.imshow(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa072a48",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"/home/w/757/multiplexed-pixels/plenoxels/blender_data/lego_gen12/train_multilens_16_black\"\n",
    "rendered_views_path = \"/home/wl757/multiplexed-pixels/plenoxels/jax_logs10/original2/multilens16_5img_5679_and59\"\n",
    "dir_name = f\"/home/wl757/multiplexed-pixels/plenoxels/blender_data/lego_gen12/multilens_16_dls_{d_lens_sensor}_5views_sensor800_img5679_and59\"\n",
    "selected_views = [50, 59, 60, 70, 90]\n",
    "\n",
    "\n",
    "def get_rays_per_pixel(H, W, comap_yx):\n",
    "    per_pixel = np.zeros((sensor_size, sensor_size, MAX_PER_PIXEL, 3)).astype(np.uint32)\n",
    "    mask = np.zeros((sensor_size, sensor_size, MAX_PER_PIXEL)).astype(float)\n",
    "    cnt = np.zeros((sensor_size, sensor_size)).astype(np.uint8)\n",
    "    for a in range(sensor_size):\n",
    "        for b in range(sensor_size):\n",
    "            for l in range(NUM_LENS):\n",
    "                x = comap_yx[l, b, a, 1]\n",
    "                y = comap_yx[l, b, a, 0]\n",
    "\n",
    "                if x != -1 and y != -1:\n",
    "                    per_pixel[a, b, cnt[a, b]] = np.array([x, y, l])\n",
    "                    mask[a, b, cnt[a, b]] = 1.0\n",
    "                    cnt[a, b] += 1\n",
    "    return per_pixel, mask, cnt\n",
    "\n",
    "\n",
    "def max_overlapping_pixels(comap_yx):\n",
    "    maps_pixel_to_rays, mask, cnt_mpp = get_rays_per_pixel(\n",
    "        sensor_size, sensor_size, comap_yx\n",
    "    )\n",
    "    rgb = np.zeros((sensor_size, sensor_size, 3))\n",
    "    sub_pixels = np.zeros((sensor_size, sensor_size, MAX_PER_PIXEL, 3))\n",
    "    cnt_pixels = np.zeros((sensor_size, sensor_size)).astype(np.int)\n",
    "    for i_index in range(sensor_size):\n",
    "        for j_index in range(sensor_size):\n",
    "            for cnt_rays in range(maps_pixel_to_rays.shape[2]):  # over MAX_PER_PIXEL\n",
    "                x_index = maps_pixel_to_rays[i_index, j_index, cnt_rays, 0]  # height\n",
    "                y_index = maps_pixel_to_rays[i_index, j_index, cnt_rays, 1]  # width\n",
    "                l_index = maps_pixel_to_rays[i_index, j_index, cnt_rays, 2]  # lens\n",
    "\n",
    "                cnt = cnt_pixels[i_index, j_index]\n",
    "                sub_pixels[i_index, j_index, cnt] = np.array(\n",
    "                    [x_index, y_index, l_index]\n",
    "                )\n",
    "                cnt_pixels[i_index, j_index] += 1\n",
    "    return sub_pixels, cnt_pixels\n",
    "\n",
    "\n",
    "def generate(comap_yx, base):\n",
    "    maps_pixel_to_rays, mask, cnt_mpp = get_rays_per_pixel(\n",
    "        sensor_size, sensor_size, comap_yx\n",
    "    )\n",
    "    u = int(np.max(comap_yx[0, :, :, :], axis=(0, 1, 2)) + 1)\n",
    "    sub_lens = np.zeros((NUM_LENS, u, u, 3))\n",
    "\n",
    "    for j in range(NUM_LENS):\n",
    "        im_gt = (\n",
    "            imageio.imread(f\"{rendered_views_path}/r_{base}_{j}.png\").astype(np.float32)\n",
    "            / 255.0\n",
    "        )\n",
    "        #             im_gt = imageio.imread(f'/home/vitran/plenoxels/output_multilens_16json/renaming/r_{base}_{j}.png').astype(np.float32) / 255.0\n",
    "        #             im_gt = imageio.imread(f\"/home/vitran/plenoxels/jax_logs10/original2/r_{base}_{j}.png\").astype(np.float32) / 255.0 #multilens 100\n",
    "        a = int(np.max(comap_yx[0, :, :, :], axis=(0, 1, 2))) + 1\n",
    "        im_gt = resize(im_gt, (a, a), anti_aliasing=True)\n",
    "        sub_lens[j, :, :, :] = im_gt[:, :, :3]\n",
    "\n",
    "    rgb = np.zeros((sensor_size, sensor_size, 3)).astype(float)\n",
    "    cnt_subpixels = np.zeros((sensor_size, sensor_size), dtype=int)\n",
    "\n",
    "    for i_index in range(sensor_size):\n",
    "        for j_index in range(sensor_size):\n",
    "            for cnt_rays in range(maps_pixel_to_rays.shape[2]):  # over MAX_PER_PIXEL\n",
    "                x_index = maps_pixel_to_rays[i_index, j_index, cnt_rays, 0]  # height\n",
    "                y_index = maps_pixel_to_rays[i_index, j_index, cnt_rays, 1]  # width\n",
    "                l_index = maps_pixel_to_rays[i_index, j_index, cnt_rays, 2]  # lens\n",
    "                if mask[i_index, j_index, cnt_rays] == 1:\n",
    "                    rgb[i_index, j_index] += sub_lens[l_index, x_index, y_index, :]\n",
    "                    cnt_subpixels[i_index, j_index] += 1\n",
    "            rgb[i_index, j_index] = rgb[i_index, j_index] / MAX_PER_PIXEL\n",
    "    rgb = np.concatenate((rgb, np.ones((sensor_size, sensor_size, 1))), axis=2)\n",
    "    return rgb\n",
    "\n",
    "\n",
    "os.makedirs(dir_name, exist_ok=True)\n",
    "for base in selected_views:\n",
    "    rgb = generate(comap_yx, base)\n",
    "    rgb = Image.fromarray((rgb * 255).astype(\"uint8\"))  # (a*255).astype('uint8'))\n",
    "    plt.imshow(rgb)\n",
    "    rgb.save(f\"{dir_name}/r_{base}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccd439c-5414-4954-8bcf-91b8e8c9435e",
   "metadata": {},
   "source": [
    "Generate the json file points to the newly generated multiplexed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f221159-fe19-44d4-b8f8-ea69a4ff5c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = open('/home/vitran/plenoxels/blender_data/lego_gen10/transforms_train_multilens_100.json')\n",
    "file = open(\n",
    "    \"/home/vitran/plenoxels/blender_data/lego_gen12/transforms_train_multilens_16_black.json\"\n",
    ")\n",
    "#              /home/vitran/plenoxels/blender_data/lego_gen12/transforms_train_multilens_16_5views_img5679_and59.json\n",
    "org_json = json.load(file)\n",
    "new_frames = []\n",
    "for i, frame in enumerate(org_json[\"frames\"]):\n",
    "    index = frame[\"file_path\"].split(\"/\")[-1]\n",
    "    frame[\"file_path\"] = f\"./train_multilens_16_wide/{index}\"\n",
    "    new_frames.append(frame)\n",
    "file.close()\n",
    "\n",
    "file.close()\n",
    "org_json[\"frames\"] = new_frames\n",
    "with open(\n",
    "    \"/home/vitran/plenoxels/blender_data/lego_gen12/transforms_train_multilens_16_wide.json\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    json.dump(org_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f84669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = open('/home/vitran/plenoxels/blender_data/lego_gen10/transforms_train_multilens_100.json')\n",
    "file = open(\"/home/vitran/plenoxels/blender_data/lego/transforms_test.json\")\n",
    "#              /home/vitran/plenoxels/blender_data/lego_gen12/transforms_train_multilens_16_5views_img5679_and59.json\n",
    "org_json = json.load(file)\n",
    "new_frames = []\n",
    "for i, frame in enumerate(org_json[\"frames\"]):\n",
    "    index = frame[\"file_path\"].split(\"/\")[-1]\n",
    "    frame[\"file_path\"] = f\"./test_focal/{index}\"\n",
    "    new_frames.append(frame)\n",
    "file.close()\n",
    "\n",
    "file.close()\n",
    "org_json[\"frames\"] = new_frames\n",
    "org_json[\"camera_angle_x\"] = 0.9\n",
    "with open(\n",
    "    \"/home/vitran/plenoxels/blender_data/lego_gen12/transforms_test_focal.json\", \"w\"\n",
    ") as f:\n",
    "    json.dump(org_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bc65b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    path = f\"/home/vitran/plenoxels/blender_data/lego_gen12/train_multilens_100_copy/r_0_{i}.png\"\n",
    "    img = imageio.imread(f\"{path}\")\n",
    "    imageio.imwrite(\n",
    "        f\"/home/vitran/plenoxels/blender_data/lego_gen12/train_multilens_100/r_90_{i}.png\",\n",
    "        img,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1660e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xaxis = [10, 15, 18, 20]\n",
    "yaxis = []\n",
    "for dls in xaxis:\n",
    "    path = f\"/home/vitran/plenoxels/jax_logs12/dls_psnr_multiplex16_dls_{dls}_5views_sensor800_img5679_and59_epoch/log.txt\"\n",
    "    with open(path) as f:\n",
    "        lines = f.readlines()\n",
    "        print(f\"4x4: Distance {dls}:{lines[-1]}\")\n",
    "        yaxis.append(float(lines[-1].split(\" \")[-1]))\n",
    "plt.scatter(xaxis, yaxis, label=\"4x4\")\n",
    "plt.axhline(y=17.021165017950217, color=\"r\", linestyle=\"-\", label=\"baseline\")\n",
    "# plt.title('grid of 4x4 sublens')\n",
    "\n",
    "xaxis = [10, 12, 14, 18, 25]\n",
    "yaxis = []\n",
    "for dls in xaxis:\n",
    "    path = f\"/home/vitran/plenoxels/jax_logs11/dls_psnr_multiplex100_dls_{dls}_5views_sensor800_img5679_and_59/log.txt\"\n",
    "    with open(path) as f:\n",
    "        lines = f.readlines()\n",
    "        print(f\"10x10: Distance {dls}:{lines[-1]}\")\n",
    "        yaxis.append(float(lines[-1].split(\" \")[-1]))\n",
    "plt.scatter(xaxis, yaxis, label=\"10x10\")\n",
    "plt.legend()\n",
    "# plt.title('grid of 10x10 sublens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d3428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xaxis = [10, 12, 14, 18, 25]\n",
    "yaxis = []\n",
    "for dls in xaxis:\n",
    "    path = f\"/home/vitran/plenoxels/jax_logs11/dls_psnr_multiplex100_dls_{dls}_5views_sensor800_img5679_and_59/log.txt\"\n",
    "    with open(path) as f:\n",
    "        lines = f.readlines()\n",
    "        print(lines[-1])\n",
    "        yaxis.append(float(lines[-1].split(\" \")[-1]))\n",
    "plt.scatter(xaxis, yaxis)\n",
    "plt.title(\"grid of 10x10 sublens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed03a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gaussian_splatting",
   "language": "python",
   "name": "gaussian_splatting"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
