{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2f3b9a1",
   "metadata": {},
   "source": [
    "# Multiplexing Pixels Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bc669e-7311-4be2-9a16-e2a2f5d3db79",
   "metadata": {},
   "source": [
    "## Generating multiplexed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c86cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from typing import Tuple, List\n",
    "\n",
    "\n",
    "def get_comap(\n",
    "    num_lens: int, d_lens_sensor: int, H: int, W: int\n",
    ") -> Tuple[np.ndarray, List[int]]:\n",
    "    # Verify input and calculate the grid dimensions\n",
    "    if math.sqrt(num_lens) ** 2 == num_lens:\n",
    "        num_lenses_yx = [int(math.sqrt(num_lens)), int(math.sqrt(num_lens))]\n",
    "    else:\n",
    "        print(\"Number of sublens should be a square number\")\n",
    "        assert False\n",
    "\n",
    "    # Calculate microlens dimensions in pixels based on d_lens_sensor\n",
    "    base_microlens_size = min(H // num_lenses_yx[0], W // num_lenses_yx[1]) // 12\n",
    "    microlens_height = int(base_microlens_size * d_lens_sensor)\n",
    "    microlens_height = microlens_height - (\n",
    "        microlens_height % 2\n",
    "    )  # Make dimensions even for convenience\n",
    "    microlens_width = microlens_height  # Keep microlenses square\n",
    "    comap_yx = -np.ones((num_lens, H, W, 2))\n",
    "\n",
    "    # Calculate positions for microlenses to distribute from edge to edge\n",
    "    if num_lenses_yx[0] > 1:\n",
    "        y_positions = np.linspace(\n",
    "            microlens_height // 2,  # First lens centered at top edge + half lens height\n",
    "            H\n",
    "            - microlens_height\n",
    "            // 2,  # Last lens centered at bottom edge - half lens height\n",
    "            num_lenses_yx[0],\n",
    "        )\n",
    "    else:\n",
    "        y_positions = np.array([H // 2])  # If only one row, place it in the center\n",
    "    if num_lenses_yx[1] > 1:\n",
    "        x_positions = np.linspace(\n",
    "            microlens_width // 2,  # First lens centered at left edge + half lens width\n",
    "            W\n",
    "            - microlens_width\n",
    "            // 2,  # Last lens centered at right edge - half lens width\n",
    "            num_lenses_yx[1],\n",
    "        )\n",
    "    else:\n",
    "        x_positions = np.array([W // 2])  # If only one column, place it in the center\n",
    "\n",
    "    for i in range(num_lens):\n",
    "        row, col = i // num_lenses_yx[1], i % num_lenses_yx[1]\n",
    "        center_y, center_x = int(y_positions[row]), int(x_positions[col])\n",
    "        start_y = int(max(0, center_y - microlens_height // 2))\n",
    "        end_y = int(min(H, center_y + microlens_height // 2))\n",
    "        start_x = int(max(0, center_x - microlens_width // 2))\n",
    "        end_x = int(min(W, center_x + microlens_width // 2))\n",
    "\n",
    "        for y in range(start_y, end_y):\n",
    "            for x in range(start_x, end_x):\n",
    "                local_y, local_x = y - start_y, x - start_x\n",
    "                comap_yx[i, y, x, 0] = local_y\n",
    "                comap_yx[i, y, x, 1] = local_x\n",
    "\n",
    "    # Return the original dimension as second return value\n",
    "    dim_lens_lf_yx = [microlens_height, microlens_width]\n",
    "    return comap_yx, dim_lens_lf_yx\n",
    "\n",
    "\n",
    "def read_images(num_lens, model_path, base):\n",
    "    images = []\n",
    "    for j in range(num_lens):\n",
    "        sub_lens_path = f\"r_{base}_{j}.png\"\n",
    "        im_gt = (\n",
    "            imageio.imread(f\"{model_path}/{sub_lens_path}\").astype(np.float32) / 255.0\n",
    "        )\n",
    "        im_tensor = torch.from_numpy(im_gt[:, :, :3]).permute(2, 0, 1).to(device)\n",
    "        images.append(im_tensor)  # Keep only RGB channels\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "def get_max_overlap(comap_yx, num_lens, H, W):\n",
    "    overlap_count = torch.zeros(H, W, dtype=torch.int32, device=device)\n",
    "    for i in range(num_lens):\n",
    "        valid_mask = comap_yx[i][:, :, 1] != -1\n",
    "        overlap_count += valid_mask\n",
    "    return overlap_count.max()\n",
    "\n",
    "\n",
    "def generate_sub_images(images, comap_yx, dim_lens_lf_yx, num_lens, sensor_size):\n",
    "    sub_images = torch.zeros(\n",
    "        num_lens, 3, sensor_size, sensor_size, device=device, dtype=torch.float32\n",
    "    )\n",
    "\n",
    "    # Create a mapping from comap_yx index to images index\n",
    "    grid_size = int(math.sqrt(num_lens))\n",
    "    idx = torch.arange(grid_size, device=device)\n",
    "    grid_i, grid_j = torch.meshgrid(idx, idx, indexing=\"ij\")\n",
    "    mapping = ((grid_size - 1 - grid_i) + (grid_size - 1 - grid_j) * grid_size).reshape(\n",
    "        -1\n",
    "    )\n",
    "\n",
    "    images_tensor = torch.stack(images, dim=0).to(device)\n",
    "    selected_images = images_tensor[mapping]\n",
    "    resized_images = F.interpolate(\n",
    "        selected_images,\n",
    "        size=(dim_lens_lf_yx[0], dim_lens_lf_yx[1]),\n",
    "        mode=\"bilinear\",\n",
    "        align_corners=False,\n",
    "    )\n",
    "\n",
    "    for i in range(num_lens):\n",
    "        # sub_image = torch.zeros(3, sensor_size, sensor_size, device=device, dtype=torch.float32)\n",
    "        y_coords = comap_yx[i, :, :, 0]\n",
    "        x_coords = comap_yx[i, :, :, 1]\n",
    "\n",
    "        valid_mask = (\n",
    "            (y_coords != -1)\n",
    "            & (x_coords != -1)\n",
    "            & (y_coords >= 0)\n",
    "            & (y_coords < dim_lens_lf_yx[0])\n",
    "            & (x_coords >= 0)\n",
    "            & (x_coords < dim_lens_lf_yx[1])\n",
    "        )\n",
    "\n",
    "        if valid_mask.any():\n",
    "            y_indices, x_indices = torch.where(valid_mask)\n",
    "            y_src = y_coords[valid_mask].int()\n",
    "            x_src = x_coords[valid_mask].int()\n",
    "        sub_images[i, :, y_indices, x_indices] = resized_images[i, :, y_src, x_src]\n",
    "\n",
    "    return sub_images\n",
    "\n",
    "\n",
    "def generate(images, comap_yx, dim_lens_lf_yx, num_lens, H, W, max_overlap):\n",
    "    grid_size = int(math.sqrt(num_lens))\n",
    "    idx = torch.arange(grid_size, device=device)\n",
    "    grid_i, grid_j = torch.meshgrid(idx, idx, indexing=\"ij\")\n",
    "    mapping = ((grid_size - 1 - grid_i) + (grid_size - 1 - grid_j) * grid_size).reshape(\n",
    "        -1\n",
    "    )\n",
    "\n",
    "    images_tensor = torch.stack(images, dim=0).to(device)\n",
    "    selected_images = images_tensor[mapping]\n",
    "    resized_images = F.interpolate(\n",
    "        selected_images,\n",
    "        size=(dim_lens_lf_yx[0], dim_lens_lf_yx[1]),\n",
    "        mode=\"bilinear\",\n",
    "        align_corners=False,\n",
    "    )\n",
    "\n",
    "    output_image = torch.zeros(3, H, W, device=device, dtype=torch.float32)\n",
    "    for i in range(num_lens):\n",
    "        y_coords = comap_yx[i, :, :, 0]\n",
    "        x_coords = comap_yx[i, :, :, 1]\n",
    "\n",
    "        valid_mask = (\n",
    "            (y_coords != -1)\n",
    "            & (x_coords != -1)\n",
    "            & (y_coords >= 0)\n",
    "            & (y_coords < dim_lens_lf_yx[0])\n",
    "            & (x_coords >= 0)\n",
    "            & (x_coords < dim_lens_lf_yx[1])\n",
    "        )\n",
    "\n",
    "        # Only process this microlens if there are any valid mapping positions.\n",
    "        if valid_mask.any():\n",
    "            # Get 2D indices within the sub-image where valid_mask is True.\n",
    "            y_indices, x_indices = torch.where(valid_mask)\n",
    "            y_src = y_coords[valid_mask].long()\n",
    "            x_src = x_coords[valid_mask].long()\n",
    "            output_image[:, y_indices, x_indices] += resized_images[i, :, y_src, x_src]\n",
    "\n",
    "    output_image = torch.div(output_image, max_overlap)\n",
    "    return output_image\n",
    "\n",
    "\n",
    "def plot_sub_images(sub_images, num_lens):\n",
    "    grid_size = int(np.sqrt(num_lens))\n",
    "    fig, axes = plt.subplots(grid_size, grid_size, figsize=(15, 15))\n",
    "\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            idx = i * grid_size + j\n",
    "            axes[i, j].imshow(sub_images[idx].cpu().permute(1, 2, 0).numpy())\n",
    "            axes[i, j].set_title(f\"Microlens {idx}\")\n",
    "            axes[i, j].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "NUM_LENS = 16\n",
    "SENSOR_SIZE = 800\n",
    "d_lens_sensor = 18\n",
    "model_path = \"/home/wl757/multiplexed-pixels/plenoxels/blender_data/lego_gen12/new_multiplexed_views\"\n",
    "base = \"59\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Generate coordinate mapping\n",
    "comap_yx, dim_lens_lf_yx = get_comap(NUM_LENS, d_lens_sensor, SENSOR_SIZE, SENSOR_SIZE)\n",
    "print(dim_lens_lf_yx)\n",
    "# plt.imshow(comap_yx[0, :, :, 0])\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "comap_yx = torch.from_numpy(comap_yx).to(device)\n",
    "\n",
    "# Generate and get sub-images\n",
    "images = read_images(NUM_LENS, model_path, base)\n",
    "max_overlap = get_max_overlap(comap_yx, NUM_LENS, SENSOR_SIZE, SENSOR_SIZE)\n",
    "combined = generate(\n",
    "    images, comap_yx, dim_lens_lf_yx, NUM_LENS, SENSOR_SIZE, SENSOR_SIZE, max_overlap\n",
    ")\n",
    "print(max_overlap)\n",
    "\n",
    "print(combined.min(), combined.max())\n",
    "plt.imshow(combined.cpu().permute(1, 2, 0).numpy())\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a0821e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from kornia.enhance.equalization import equalize_clahe\n",
    "\n",
    "with torch.autograd.detect_anomaly():\n",
    "    img = torch.rand((2, 3, 10, 20), requires_grad=True)\n",
    "    res = equalize_clahe(img, slow_and_differentiable=True)\n",
    "    res.sum().backward()\n",
    "    print(img.grad, img.grad.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1244e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "\n",
    "def get_comap(num_lens, d_lens_sensor, H, W):\n",
    "    if math.sqrt(num_lens) ** 2 == num_lens:\n",
    "        num_lenses_yx = [int(math.sqrt(num_lens)), int(math.sqrt(num_lens))]\n",
    "    else:\n",
    "        print(\"Number of sublens should be a square number\")\n",
    "        assert False\n",
    "\n",
    "    base_microlens_size = min(H // num_lenses_yx[0], W // num_lenses_yx[1]) // 12\n",
    "    microlens_height = int(base_microlens_size * d_lens_sensor)\n",
    "    microlens_height = microlens_height - (\n",
    "        microlens_height % 2\n",
    "    )  # Make dimensions even for convenience\n",
    "    microlens_width = microlens_height  # Keep microlenses square\n",
    "    comap_yx = -np.ones((num_lens, H, W, 2))\n",
    "\n",
    "    if num_lenses_yx[0] > 1:\n",
    "        y_positions = np.linspace(\n",
    "            microlens_height // 2,  # First lens centered at top edge + half lens height\n",
    "            H\n",
    "            - microlens_height\n",
    "            // 2,  # Last lens centered at bottom edge - half lens height\n",
    "            num_lenses_yx[0],\n",
    "        )\n",
    "    else:\n",
    "        y_positions = np.array([H // 2])  # If only one row, place it in the center\n",
    "    if num_lenses_yx[1] > 1:\n",
    "        x_positions = np.linspace(\n",
    "            microlens_width // 2,  # First lens centered at left edge + half lens width\n",
    "            W\n",
    "            - microlens_width\n",
    "            // 2,  # Last lens centered at right edge - half lens width\n",
    "            num_lenses_yx[1],\n",
    "        )\n",
    "    else:\n",
    "        x_positions = np.array([W // 2])  # If only one column, place it in the center\n",
    "\n",
    "    for i in range(num_lens):\n",
    "        row, col = i // num_lenses_yx[1], i % num_lenses_yx[1]\n",
    "        center_y, center_x = int(y_positions[row]), int(x_positions[col])\n",
    "        start_y = int(max(0, center_y - microlens_height // 2))\n",
    "        end_y = int(min(H, center_y + microlens_height // 2))\n",
    "        start_x = int(max(0, center_x - microlens_width // 2))\n",
    "        end_x = int(min(W, center_x + microlens_width // 2))\n",
    "\n",
    "        for y in range(start_y, end_y):\n",
    "            for x in range(start_x, end_x):\n",
    "                local_y, local_x = y - start_y, x - start_x\n",
    "                comap_yx[i, y, x, 0] = local_y\n",
    "                comap_yx[i, y, x, 1] = local_x\n",
    "\n",
    "    dim_lens_lf_yx = [microlens_height, microlens_width]\n",
    "    return comap_yx, dim_lens_lf_yx\n",
    "\n",
    "\n",
    "def read_images(num_lens, model_path, base):\n",
    "    images = []\n",
    "    for j in range(num_lens):\n",
    "        sub_lens_path = f\"r_{base}_{j}.png\"\n",
    "        im_gt = (\n",
    "            imageio.imread(f\"{model_path}/{sub_lens_path}\").astype(np.float32) / 255.0\n",
    "        )\n",
    "        im_tensor = torch.from_numpy(im_gt[:, :, :3]).permute(2, 0, 1).to(device)\n",
    "        images.append(im_tensor)  # Keep only RGB channels\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "def get_max_overlap(comap_yx, num_lens, H, W):\n",
    "    overlap_count = torch.zeros(H, W, dtype=torch.int32, device=device)\n",
    "    for i in range(num_lens):\n",
    "        valid_mask = comap_yx[i][:, :, 1] != -1\n",
    "        overlap_count += valid_mask\n",
    "    return overlap_count.max()\n",
    "\n",
    "\n",
    "NUM_LENS = 16\n",
    "SENSOR_SIZE = 400\n",
    "d_lens_sensor = 19\n",
    "model_path = \"/home/wl757/multiplexed-pixels/plenoxels/blender_data/lego_gen12/train_multilens_16_black\"\n",
    "base = \"59\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Generate coordinate mapping\n",
    "comap_yx, dim_lens_lf_yx = get_comap(NUM_LENS, d_lens_sensor, SENSOR_SIZE, SENSOR_SIZE)\n",
    "print(dim_lens_lf_yx)\n",
    "# plt.imshow(comap_yx[0, :, :, 0])\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "comap_yx = torch.from_numpy(comap_yx).to(device)\n",
    "\n",
    "# Generate and get sub-images\n",
    "images = read_images(NUM_LENS, model_path, base)\n",
    "sub_images = generate_sub_images(\n",
    "    images, comap_yx, dim_lens_lf_yx, NUM_LENS, SENSOR_SIZE\n",
    ")\n",
    "max_overlap = get_max_overlap(comap_yx, NUM_LENS, SENSOR_SIZE, SENSOR_SIZE)\n",
    "print(max_overlap)\n",
    "\n",
    "# Plot all sub-images\n",
    "# plot_sub_images(sub_images, NUM_LENS)\n",
    "combined = torch.sum(sub_images, axis=0)\n",
    "combined = combined / combined.max()\n",
    "plt.imshow(combined.cpu().permute(1, 2, 0).numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e973ab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from kornia import enhance\n",
    "import torch\n",
    "\n",
    "\n",
    "def get_comap(num_lens, d_lens_sensor, H, W):\n",
    "    if math.sqrt(num_lens) ** 2 == num_lens:\n",
    "        num_lenses_yx = [int(math.sqrt(num_lens)), int(math.sqrt(num_lens))]\n",
    "    else:\n",
    "        print(\"Number of sublens should be a square number\")\n",
    "        assert False\n",
    "\n",
    "    # Calculate microlens dimensions in pixels based on d_lens_sensor\n",
    "    base_microlens_size = min(H // num_lenses_yx[0], W // num_lenses_yx[1]) // 12\n",
    "    microlens_height = int(base_microlens_size * d_lens_sensor)\n",
    "    microlens_height = microlens_height - (\n",
    "        microlens_height % 2\n",
    "    )  # Make dimensions even for convenience\n",
    "    microlens_width = microlens_height  # Keep microlenses square\n",
    "    comap_yx = -np.ones((num_lens, H, W, 2))\n",
    "\n",
    "    # Calculate positions for microlenses to distribute from edge to edge\n",
    "    if num_lenses_yx[0] > 1:\n",
    "        y_positions = np.linspace(\n",
    "            microlens_height // 2,  # First lens centered at top edge + half lens height\n",
    "            H\n",
    "            - microlens_height\n",
    "            // 2,  # Last lens centered at bottom edge - half lens height\n",
    "            num_lenses_yx[0],\n",
    "        )\n",
    "    else:\n",
    "        y_positions = np.array([H // 2])  # If only one row, place it in the center\n",
    "    if num_lenses_yx[1] > 1:\n",
    "        x_positions = np.linspace(\n",
    "            microlens_width // 2,  # First lens centered at left edge + half lens width\n",
    "            W\n",
    "            - microlens_width\n",
    "            // 2,  # Last lens centered at right edge - half lens width\n",
    "            num_lenses_yx[1],\n",
    "        )\n",
    "    else:\n",
    "        x_positions = np.array([W // 2])  # If only one column, place it in the center\n",
    "\n",
    "    for i in range(num_lens):\n",
    "        row, col = i // num_lenses_yx[1], i % num_lenses_yx[1]\n",
    "        center_y, center_x = int(y_positions[row]), int(x_positions[col])\n",
    "        start_y = int(max(0, center_y - microlens_height // 2))\n",
    "        end_y = int(min(H, center_y + microlens_height // 2))\n",
    "        start_x = int(max(0, center_x - microlens_width // 2))\n",
    "        end_x = int(min(W, center_x + microlens_width // 2))\n",
    "\n",
    "        for y in range(start_y, end_y):\n",
    "            for x in range(start_x, end_x):\n",
    "                local_y, local_x = y - start_y, x - start_x\n",
    "                comap_yx[i, y, x, 0] = local_y\n",
    "                comap_yx[i, y, x, 1] = local_x\n",
    "\n",
    "    # Return the original dimension as second return value\n",
    "    dim_lens_lf_yx = [microlens_height, microlens_width]\n",
    "    return comap_yx, dim_lens_lf_yx\n",
    "\n",
    "\n",
    "def read_images(num_lens, model_path, base):\n",
    "    images = []\n",
    "    for j in range(num_lens):\n",
    "        sub_lens_path = f\"r_{base}_{j}.png\"\n",
    "        im_gt = (\n",
    "            imageio.imread(f\"{model_path}/{sub_lens_path}\").astype(np.float32) / 255.0\n",
    "        )\n",
    "        images.append(im_gt[:, :, :3])  # Keep only RGB channels\n",
    "    return images\n",
    "\n",
    "\n",
    "def generate_alpha_map(comap_yx, num_lens, H, W):\n",
    "    overlap_count = np.zeros((H, W), dtype=np.int32)\n",
    "\n",
    "    for i in range(num_lens):\n",
    "        valid_mask = comap_yx[i, :, :, 0] != -1\n",
    "        overlap_count += valid_mask\n",
    "\n",
    "    alpha_map = np.zeros((H, W))\n",
    "    non_zero_mask = overlap_count > 0\n",
    "    alpha_map[non_zero_mask] = 1.0 / overlap_count[non_zero_mask]\n",
    "    return alpha_map, overlap_count\n",
    "\n",
    "\n",
    "NUM_LENS = 16\n",
    "SENSOR_SIZE = 800\n",
    "d_lens_sensor = 20\n",
    "model_path = \"/home/wl757/multiplexed-pixels/plenoxels/blender_data/lego_gen12/train_multilens_16_black\"\n",
    "base = \"59\"\n",
    "\n",
    "# Generate coordinate mapping\n",
    "comap_yx, dim_lens_lf_yx = get_comap(NUM_LENS, d_lens_sensor, SENSOR_SIZE, SENSOR_SIZE)\n",
    "# print(dim_lens_lf_yx)\n",
    "# plt.imshow(comap_yx[0, :, :, 0])\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "alpha_map, overlap_count = generate_alpha_map(\n",
    "    comap_yx, NUM_LENS, SENSOR_SIZE, SENSOR_SIZE\n",
    ")\n",
    "# plt.imshow(alpha_map)\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "# Generate and get sub-images\n",
    "images = read_images(NUM_LENS, model_path, base)\n",
    "sub_images = generate_sub_images(\n",
    "    images, comap_yx, dim_lens_lf_yx, NUM_LENS, SENSOR_SIZE\n",
    ")\n",
    "\n",
    "# Plot all sub-images\n",
    "# plot_sub_images(sub_images, NUM_LENS)\n",
    "combined = np.sum(sub_images, axis=0)\n",
    "output = np.zeros((SENSOR_SIZE, SENSOR_SIZE, 3))\n",
    "for image in sub_images:\n",
    "    rgb = image[:, :, :3]\n",
    "    alpha = image[:, :, 3]\n",
    "    output += rgb * alpha[:, :, np.newaxis]\n",
    "combined_rgb = combined[:, :, :3]\n",
    "print(\"overlap max: \", overlap_count.max())\n",
    "print(\"overlap min: \", overlap_count.min())\n",
    "combined_output = combined_rgb / overlap_count.max()\n",
    "# combined_output = combined_output / combined_output.max()\n",
    "print(combined_output.min(), combined_output.max())\n",
    "plt.imshow(combined_rgb / combined_rgb.max())\n",
    "plt.show()\n",
    "plt.imshow(combined_output)\n",
    "plt.show()\n",
    "plt.imshow(\n",
    "    enhance.equalize(torch.from_numpy(combined_output).permute(2, 0, 1))\n",
    "    .permute(1, 2, 0)\n",
    "    .detach()\n",
    "    .numpy()\n",
    ")\n",
    "plt.show()\n",
    "plt.imshow(combined)\n",
    "plt.show()\n",
    "plt.imshow(output)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076f27ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def get_comap(num_lens, d_lens_sensor, H, W):\n",
    "    if math.sqrt(num_lens) ** 2 == num_lens:\n",
    "        num_lenses_yx = [int(math.sqrt(num_lens)), int(math.sqrt(num_lens))]\n",
    "    else:\n",
    "        print(\"Number of sublens should be a square number\")\n",
    "        assert False\n",
    "\n",
    "    base_microlens_size = min(H // num_lenses_yx[0], W // num_lenses_yx[1]) // 12\n",
    "    microlens_height = int(base_microlens_size * d_lens_sensor)\n",
    "    microlens_height = microlens_height - (\n",
    "        microlens_height % 2\n",
    "    )  # Make dimensions even for convenience\n",
    "    microlens_width = microlens_height  # Keep microlenses square\n",
    "    comap_yx = -np.ones((num_lens, H, W, 2))\n",
    "\n",
    "    if num_lenses_yx[0] > 1:\n",
    "        y_positions = np.linspace(\n",
    "            microlens_height // 2,  # First lens centered at top edge + half lens height\n",
    "            H\n",
    "            - microlens_height\n",
    "            // 2,  # Last lens centered at bottom edge - half lens height\n",
    "            num_lenses_yx[0],\n",
    "        )\n",
    "    else:\n",
    "        y_positions = np.array([H // 2])  # If only one row, place it in the center\n",
    "    if num_lenses_yx[1] > 1:\n",
    "        x_positions = np.linspace(\n",
    "            microlens_width // 2,  # First lens centered at left edge + half lens width\n",
    "            W\n",
    "            - microlens_width\n",
    "            // 2,  # Last lens centered at right edge - half lens width\n",
    "            num_lenses_yx[1],\n",
    "        )\n",
    "    else:\n",
    "        x_positions = np.array([W // 2])  # If only one column, place it in the center\n",
    "\n",
    "    for i in range(num_lens):\n",
    "        row, col = i // num_lenses_yx[1], i % num_lenses_yx[1]\n",
    "        center_y, center_x = int(y_positions[row]), int(x_positions[col])\n",
    "        start_y = int(max(0, center_y - microlens_height // 2))\n",
    "        end_y = int(min(H, center_y + microlens_height // 2))\n",
    "        start_x = int(max(0, center_x - microlens_width // 2))\n",
    "        end_x = int(min(W, center_x + microlens_width // 2))\n",
    "\n",
    "        for y in range(start_y, end_y):\n",
    "            for x in range(start_x, end_x):\n",
    "                local_y, local_x = y - start_y, x - start_x\n",
    "                comap_yx[i, y, x, 0] = local_y\n",
    "                comap_yx[i, y, x, 1] = local_x\n",
    "\n",
    "    # Return the original dimension as second return value\n",
    "    dim_lens_lf_yx = [microlens_height, microlens_width]\n",
    "    return comap_yx, dim_lens_lf_yx\n",
    "\n",
    "\n",
    "def read_images(num_lens, model_path, base):\n",
    "    images = []\n",
    "    for j in range(num_lens):\n",
    "        sub_lens_path = f\"r_{base}_{j}.png\"\n",
    "        im_gt = (\n",
    "            imageio.imread(f\"{model_path}/{sub_lens_path}\").astype(np.float32) / 255.0\n",
    "        )\n",
    "        im_tensor = torch.from_numpy(im_gt[:, :, :3]).permute(2, 0, 1).to(device)\n",
    "        images.append(im_tensor)  # Keep only RGB channels\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "def generate_alpha_map(comap_yx, num_lens, H, W):\n",
    "    overlap_count = np.zeros((H, W), dtype=np.int32)\n",
    "\n",
    "    for i in range(num_lens):\n",
    "        valid_mask = comap_yx[i, :, :, 0] != -1\n",
    "        overlap_count += valid_mask\n",
    "\n",
    "    alpha_map = np.zeros((H, W))\n",
    "    non_zero_mask = overlap_count > 0\n",
    "    alpha_map[non_zero_mask] = 1.0 / overlap_count[non_zero_mask]\n",
    "    return alpha_map\n",
    "\n",
    "\n",
    "def generate(images, comap_yx, dim_lens_lf_yx, num_lens, sensor_size, alpha_map):\n",
    "    # Compute the grid size (assumes num_lens is a perfect square)\n",
    "    grid_size = int(math.sqrt(num_lens))\n",
    "\n",
    "    # Vectorize the mapping from comap_yx index to images index.\n",
    "    # For each grid coordinate (i, j) in order, the mapping is computed as:\n",
    "    #   mapping[i * grid_size + j] = (grid_size - 1 - i) + (grid_size - 1 - j) * grid_size\n",
    "    idx = torch.arange(grid_size, device=device)\n",
    "    grid_i, grid_j = torch.meshgrid(idx, idx, indexing=\"ij\")\n",
    "    mapping = ((grid_size - 1 - grid_i) + (grid_size - 1 - grid_j) * grid_size).reshape(\n",
    "        -1\n",
    "    )\n",
    "\n",
    "    # Stack images into one tensor and select the images as ordered by the mapping.\n",
    "    # images_tensor shape: (N, 3, H, W) --> selected_images shape: (num_lens, 3, H, W)\n",
    "    images_tensor = torch.stack(images, dim=0).to(device)\n",
    "    selected_images = images_tensor[mapping]\n",
    "\n",
    "    # Resize all selected images at once using vectorized interpolation.\n",
    "    # The output shape will be (num_lens, 3, lens_H, lens_W)\n",
    "    resized_images = F.interpolate(\n",
    "        selected_images,\n",
    "        size=(dim_lens_lf_yx[0], dim_lens_lf_yx[1]),\n",
    "        mode=\"bilinear\",\n",
    "        align_corners=False,\n",
    "    )\n",
    "\n",
    "    output_image = torch.zeros(\n",
    "        3, sensor_size, sensor_size, device=device, dtype=torch.float32\n",
    "    )\n",
    "\n",
    "    # Loop over each microlens and accumulate its contribution.\n",
    "    for i in range(num_lens):\n",
    "        # Extract the coordinate maps for this microlens (each of shape (sensor_size, sensor_size)).\n",
    "        # The last dimension in comap_yx_torch holds [y, x] coordinates.\n",
    "        y_coords = comap_yx[i, :, :, 0]\n",
    "        x_coords = comap_yx[i, :, :, 1]\n",
    "\n",
    "        # Build a mask that marks valid pixel positions:\n",
    "        # - Coordinates must not equal -1\n",
    "        # - Must be within the bounds of the resized image dimensions.\n",
    "        valid_mask = (\n",
    "            (y_coords != -1)\n",
    "            & (x_coords != -1)\n",
    "            & (y_coords >= 0)\n",
    "            & (y_coords < dim_lens_lf_yx[0])\n",
    "            & (x_coords >= 0)\n",
    "            & (x_coords < dim_lens_lf_yx[1])\n",
    "        )\n",
    "\n",
    "        # Only process this microlens if there are any valid mapping positions.\n",
    "        if valid_mask.any():\n",
    "            # Get 2D indices within the sub-image where valid_mask is True.\n",
    "            y_indices, x_indices = torch.where(valid_mask)\n",
    "\n",
    "            y_src = y_coords[valid_mask].long()\n",
    "            x_src = x_coords[valid_mask].long()\n",
    "\n",
    "            output_image[:, y_indices, x_indices] += resized_images[\n",
    "                i, :, y_src, x_src\n",
    "            ] * alpha_map[y_indices, x_indices].unsqueeze(0)\n",
    "\n",
    "    # Clamp the final output to ensure pixel values are in the valid range [0, 1].\n",
    "    output_image = torch.clamp(output_image, 0, 1)\n",
    "\n",
    "    return output_image\n",
    "\n",
    "\n",
    "# def generate(images, comap_yx, dim_lens_lf_yx, num_lens, sensor_size, alpha_map):\n",
    "#     grid_size = int(math.sqrt(num_lens))\n",
    "#     idx = torch.arange(grid_size, device=device)\n",
    "#     grid_i, grid_j = torch.meshgrid(idx, idx, indexing='ij')\n",
    "#     mapping = ((grid_size - 1 - grid_i) + (grid_size - 1 - grid_j) * grid_size).reshape(-1)\n",
    "\n",
    "#     images_tensor = torch.stack(images, dim=0).to(device)\n",
    "#     selected_images = images_tensor[mapping]\n",
    "#     resized_images = F.interpolate(\n",
    "#         selected_images,\n",
    "#         size=(dim_lens_lf_yx[0], dim_lens_lf_yx[1]),\n",
    "#         mode='bilinear',\n",
    "#         align_corners=False\n",
    "#     )\n",
    "\n",
    "#     output_image = torch.zeros(3, sensor_size, sensor_size, device=device, dtype=torch.float32)\n",
    "\n",
    "#     for i in range(num_lens):\n",
    "#         y_coords = comap_yx[i, :, :, 0]\n",
    "#         x_coords = comap_yx[i, :, :, 1]\n",
    "\n",
    "#         valid_mask = (y_coords != -1) & (x_coords != -1) & \\\n",
    "#                      (y_coords >= 0) & (y_coords < dim_lens_lf_yx[0]) & \\\n",
    "#                      (x_coords >= 0) & (x_coords < dim_lens_lf_yx[1])\n",
    "\n",
    "#         # Only process this microlens if there are any valid mapping positions.\n",
    "#         if valid_mask.any():\n",
    "#             # Get 2D indices within the sub-image where valid_mask is True.\n",
    "#             y_indices, x_indices = torch.where(valid_mask)\n",
    "#             y_src = y_coords[valid_mask].long()\n",
    "#             x_src = x_coords[valid_mask].long()\n",
    "#             output_image[:, y_indices, x_indices] += resized_images[i, :, y_src, x_src] * alpha_map[y_indices, x_indices].unsqueeze(0)\n",
    "\n",
    "#     # Clamp the final output to ensure pixel values are in the valid range [0, 1].\n",
    "#     output_image = torch.clamp(output_image, 0, 1)\n",
    "\n",
    "#     return output_image\n",
    "\n",
    "mode_path = \"/home/wl757/multiplexed-pixels/plenoxels/blender_data/lego_gen12/train_multilens_16_black\"\n",
    "base = \"59\"\n",
    "NUM_LENS = 16\n",
    "SENSOR_SIZE = 800\n",
    "d_lens_sensor = 20  # this is the value to change for more or less multiplexing\n",
    "\n",
    "comap_yx, dim_lens_lf_yx = get_comap(NUM_LENS, d_lens_sensor, SENSOR_SIZE, SENSOR_SIZE)\n",
    "alpha_map = (\n",
    "    torch.from_numpy(generate_alpha_map(comap_yx, NUM_LENS, SENSOR_SIZE, SENSOR_SIZE))\n",
    "    .float()\n",
    "    .to(device)\n",
    ")\n",
    "plt.imshow(alpha_map.cpu().numpy())\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "comap_yx = torch.from_numpy(comap_yx).to(device)\n",
    "images = read_images(NUM_LENS, model_path, base)\n",
    "# multiplexed_image = generate(images, comap_yx, dim_lens_lf_yx, NUM_LENS, SENSOR_SIZE, alpha_map)\n",
    "sub_images = generate_sub_images(\n",
    "    images, comap_yx, dim_lens_lf_yx, NUM_LENS, SENSOR_SIZE, alpha_map\n",
    ")\n",
    "for sub_image in sub_images:\n",
    "    rgb = sub_image[:3]\n",
    "    alpha = sub_image[3]\n",
    "    plt.imshow((rgb * alpha).cpu().numpy().transpose(1, 2, 0))\n",
    "    plt.show()\n",
    "# plt.imshow(sub_images[5].cpu().numpy().transpose(1, 2, 0))\n",
    "# plt.show()\n",
    "# output_image = torch.zeros(3, SENSOR_SIZE, SENSOR_SIZE, device=device, dtype=torch.float32)\n",
    "# for sub_image in sub_images[5:7]:\n",
    "#     rgb = sub_image[:3]\n",
    "#     alpha = sub_image[3]\n",
    "#     output_image += rgb * alpha\n",
    "# output_image = torch.clamp(output_image, 0, 1)\n",
    "# plt.imshow(output_image.cpu().numpy().transpose(1, 2, 0))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9193eda9-f6c1-40f8-b9aa-f04c0b7a4624",
   "metadata": {},
   "source": [
    "Calculated how the maximum number of rays from microlens that maps to one sensor pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bca33b-74c6-4593-822e-581cfd526891",
   "metadata": {},
   "source": [
    "Generate multiplexed images, set dir_name to be the saved directory of multiplexed images, and set selected_views to be a list of view index from transform_train.json, set rendered_views_path to be the directory that contains images from the sublens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d66eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "num_lenses_yx = [4, 4]  # [10,10] #[2,1] #[1,1]# [4,4] #[1,1]# [4,4]\n",
    "MAX_PER_PIXEL = 20\n",
    "NUM_LENS = num_lenses_yx[0] * num_lenses_yx[1]\n",
    "sensor_size = 800\n",
    "d_lens_sensor = 20  # this is the value to change for more or less multiplexing\n",
    "\n",
    "\n",
    "def get_comap(num_lens, d_lens_sensor, H, W):\n",
    "    # Verify input and calculate the grid dimensions\n",
    "    if math.sqrt(num_lens) ** 2 == num_lens:\n",
    "        num_lenses_yx = [int(math.sqrt(num_lens)), int(math.sqrt(num_lens))]\n",
    "    else:\n",
    "        print(\"Number of sublens should be a square number\")\n",
    "        assert False\n",
    "\n",
    "    # Calculate microlens dimensions in pixels based on d_lens_sensor\n",
    "    base_microlens_size = min(H // num_lenses_yx[0], W // num_lenses_yx[1]) // 12\n",
    "    microlens_height = int(base_microlens_size * d_lens_sensor)\n",
    "    microlens_height = microlens_height - (\n",
    "        microlens_height % 2\n",
    "    )  # Make dimensions even for convenience\n",
    "    microlens_width = microlens_height  # Keep microlenses square\n",
    "    comap_yx = -np.ones((num_lens, H, W, 2))\n",
    "\n",
    "    # Calculate positions for microlenses to distribute from edge to edge\n",
    "    if num_lenses_yx[0] > 1:\n",
    "        y_positions = np.linspace(\n",
    "            microlens_height // 2,  # First lens centered at top edge + half lens height\n",
    "            H\n",
    "            - microlens_height\n",
    "            // 2,  # Last lens centered at bottom edge - half lens height\n",
    "            num_lenses_yx[0],\n",
    "        )\n",
    "    else:\n",
    "        y_positions = np.array([H // 2])  # If only one row, place it in the center\n",
    "    if num_lenses_yx[1] > 1:\n",
    "        x_positions = np.linspace(\n",
    "            microlens_width // 2,  # First lens centered at left edge + half lens width\n",
    "            W\n",
    "            - microlens_width\n",
    "            // 2,  # Last lens centered at right edge - half lens width\n",
    "            num_lenses_yx[1],\n",
    "        )\n",
    "    else:\n",
    "        x_positions = np.array([W // 2])  # If only one column, place it in the center\n",
    "\n",
    "    for i in range(num_lens):\n",
    "        row, col = i // num_lenses_yx[1], i % num_lenses_yx[1]\n",
    "        center_y, center_x = int(y_positions[row]), int(x_positions[col])\n",
    "        start_y = int(max(0, center_y - microlens_height // 2))\n",
    "        end_y = int(min(H, center_y + microlens_height // 2))\n",
    "        start_x = int(max(0, center_x - microlens_width // 2))\n",
    "        end_x = int(min(W, center_x + microlens_width // 2))\n",
    "\n",
    "        for y in range(start_y, end_y):\n",
    "            for x in range(start_x, end_x):\n",
    "                local_y, local_x = y - start_y, x - start_x\n",
    "                comap_yx[i, y, x, 0] = local_y\n",
    "                comap_yx[i, y, x, 1] = local_x\n",
    "\n",
    "    # Return the original dimension as second return value\n",
    "    dim_lens_lf_yx = [microlens_height, microlens_width]\n",
    "    return comap_yx, dim_lens_lf_yx\n",
    "\n",
    "\n",
    "comap_yx, _ = get_comap(16, 20, 800, 800)\n",
    "print(comap_yx.max())\n",
    "plt.imshow(comap_yx[0, :, :, 0])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.imshow(comap_yx[3, :, :, 1])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gaussian_splatting",
   "language": "python",
   "name": "gaussian_splatting"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
